---
title: "DSF"
output:
  pdf_document: default
  html_document: default
date: "2022-10-13"
---

#Spatially optimising market-based instruments on private lands for conservation
## Code to run all scenarios
### For queries please email brooke.williams@uq.edu.au or j.rhodes@uq.edu.au
##Set up 
```{r "knitr config", cache = FALSE, include=FALSE}
require("knitr")
opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```
Load packages and set working directory
```{r setup}
library(gurobi)
library(Matrix)
library(rgeos)
library(sp)
library(dplyr)
library(magrittr)
library(rgdal)
library(purrr)
library(plyr)
library(stringr)
library(parallel)
library(data.table)
library(doSNOW)
library(foreach)
library(doParallel)
library(ranger)
library(palmerpenguins)
library(tidyverse)
library(kableExtra)
library(stringi)
library(readr)
library(gtools)
rm(list=ls())
getwd()
```
```{r check-wd, echo=FALSE}
getwd()
```
Set wd, output directory, import functions and pre-processed data, define the number of simulations and the overall budget
```{r, include=FALSE}
#Set working directory - if reproducing the results this is the only line that needs to be changed
setwd("D:/Linkage/DSF code/private_land_conservation_DSF/")
#Load the required functions
source('./code/functions.R')
#Load the data
load("./preprocessing/pu.df_11.05.23.RData")
#Set number of simulations (based on sensitivity analysis - see section SM1.4 of manuscript)
sim <- 200
#Test overall budget level
b <- 20300000
b.vec <- c(1:10 * 20300000)
#Create output folders 
outfolder <- "outputs_v16"
outfoldermaps <- "outputs_v16/maps_v16"
outfoldervals <- "outputs_v16/vals_v16"
# create folder:
  if (!dir.exists(outfoldermaps)){
    dir.create(outfoldermaps, recursive = TRUE)
  } else {
    print("Dir already exists!")
  }
if (!dir.exists(outfoldervals)){
  dir.create(outfoldervals, recursive = TRUE)
} else {
  print("Dir already exists!")
}
#Check to see if there are duplicated records
duplicates <- pu.df[duplicated(pu.df), ]
#If so remove them
df.org <- pu.df[!duplicated(pu.df), ]
print("Set up complete")
```
MAIN APPROACHES AND BUDGET SCENARIOS
##Approach 4 - Integreated approach (t7) single budget 
Set up dataframe for appropriate scenario
Here we start with scenario 2 (the scenario that includes both conservation objectives and landholder preferences, or the "landholder informed" approach). In this scenario we are also using admin.mean (which is the average admin cost across all previous tenders). We allocate the same amount for each tender. 
```{r}
scen <- "approach4"
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t7", "MeanAdopt", "MeanWTA.tot", "t7.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
```
In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
```{r, include=FALSE}
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
df$npv <- min(cost$Approx_tot_investment)
```
Run through the first of simulations - this is for the first npv increment
```{r, results = FALSE, include=FALSE}
#Clean out the paralell processing folder
# List all files in the folder
files <- list.files("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)
#Run  the simulations
df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))
df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))

```
Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
```{r}
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}
```
Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes
```{r, results = FALSE, include=FALSE}
##Create a new dataframe which has all puid's (LGAs), so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
}
```
###Set up structures for the optimisation
```{r}
#Create matrix for constraint that says only 1 budget can be allocated per LGA
#Create matrix where nrow and ncol = no. planning units
matrix_data=matrix(0,nrow=length(unique(pu.df$LGA)),ncol=length(unique(pu.df$LGA)))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
m <- rbind(pu_matrix, npv.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

#Make a long string of all conservation benefit
cons.all.incre <- df_new0$cons.benefit
for (i in 1:y){
  df.name <- paste0("df_new", i)
  cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
  cons.all.incre[is.na(cons.all.incre)] = 0
}

#Make a long string of koala area (in this current formulation this is just property area)
karea.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  karea.all.incre <- c(karea.all.incre, get(df.name)$area)
  karea.all.incre[is.na(karea.all.incre)] = 0
}

#Make a long string of all area benefit
area.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  area.all.incre <- c(area.all.incre, get(df.name)$area)
  area.all.incre[is.na(area.all.incre)] = 0
}

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}

```
Set up and run the optimisation (to select priority planning units (LGA's))
```{r, results = FALSE}
model <- list()
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b)
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')

params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)

print('Solution:')
print(result$objval)
print(result$x)
save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))

```
###Export the results
```{r, results = FALSE}
#Load in base shp file for the planning units
shp.pu <- readOGR("./preprocessing/LGA_study_region_clip_project.shp")

###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#Do the same for conservation benefit
consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(pu.df$LGA)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results
make.maps(outfoldermaps, scen)
exp.vals(outfoldervals, scen)
```

##Approach 4 - Integrated approach (t7) cycling through the budgets
```{r, include=FALSE}
#If not already loaded, need this for the make maps function
shp.pu <- readOGR("./preprocessing/LGA_study_region_clip_project.shp")

scen <- "approach4"
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t7", "MeanAdopt", "MeanWTA.tot", "t7.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

#In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
df$npv <- min(cost$Approx_tot_investment)

#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "./preprocessing/par/"
# List all files in the folder
files <- list.files("./preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)
#Run  the simulations
df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))
df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

#Add se and sd values
llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))

#Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
#y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y

#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}

#Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes
##Create a new dataframe which has all puid's, so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
  
}
###Set up structures for the optimisation
#Create matrix for constraint that says only 1 budget can be allocated per LGA
#Create matrix where nrow and ncol = no. planning units
df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=nrow(df_new),ncol=nrow(df_new))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
  #Hack - make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
m <- rbind(pu_matrix, npv.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

#Make a long string of koala area
karea.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  karea.all.incre <- c(karea.all.incre, get(df.name)$area)
  karea.all.incre[is.na(karea.all.incre)] = 0
}

#Make a long string of all conservation benefit
cons.all.incre <- df_new0$cons.benefit
for (i in 1:y){
  df.name <- paste0("df_new", i)
  cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
  cons.all.incre[is.na(cons.all.incre)] = 0
}

#Make a long string of all area benefit
area.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  area.all.incre <- c(area.all.incre, get(df.name)$area)
  area.all.incre[is.na(area.all.incre)] = 0
}

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}


for (b in b.vec[1:10]){

#Set up and run the optimisation (to select priority planning units (LGA's))
model <- list()
#model$A <- matrix(c(data_frame_test$npv), nrow=1)
#nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b)
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')

params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)

print('Solution:')
print(result$objval)
print(result$x)
#save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))
save(result, file = paste0(outfolder, "./", scen, "_", b, ".RData"))

#load("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/scenario2_101500000.RData")
###Export the results
###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#Do the same for conservation benefit
consben.matrix <- matrix(cons.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results

make.maps(outfoldermaps, scen)
exp.vals(outfoldervals, scen)

}

save(budget.matrix, file = "./preprocessing/budget.matrix_approach4.RData")
save(consben.matrix, file = "./preprocessing/consben.matrix_approach4.RData")
save(area.matrix, file = "./preprocessing/area.matrix_approach4.RData")
```

##Approach 2 - Landholder informed single budget 
Set up dataframe for appropriate scenario
Here we start with scenario 2 (the scenario that includes both conservation objectives and landholder preferences, or the "landholder informed" approach). In this scenario we are also using admin.mean (which is the average admin cost across all previous tenders). We allocate the same amount for each tender. 
```{r}
scen <- "approach2"
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t0", "MeanAdopt", "MeanWTA.tot", "t0.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
```
In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
```{r, include=FALSE}
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
min(cost$Approx_tot_investment)
df$npv <- 1126260
```
Run through the first of simulations - this is for the first npv increment
```{r, results = FALSE, include=FALSE}
#Clean out the paralell processing folder
# List all files in the folder
files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)
#Run  the simulations
df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))
df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))

```
Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
```{r}
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}
```
Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes
```{r, results = FALSE, include=FALSE}
##Create a new dataframe which has all puid's (LGAs), so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
}
```
###Set up structures for the optimisation
Create matrix for constraint that says only 1 budget can be allocated per LGA
```{r}
#Create matrix where nrow and ncol = no. planning units
#df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=length(unique(pu.df$LGA)),ncol=length(unique(pu.df$LGA)))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
m <- rbind(pu_matrix, npv.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

#Make a long string of all conservation benefit
cons.all.incre <- df_new0$cons.benefit
for (i in 1:y){
  df.name <- paste0("df_new", i)
  cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
  cons.all.incre[is.na(cons.all.incre)] = 0
}

#Make a long string of koala area (in this current formulation this is just property area)
karea.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  karea.all.incre <- c(karea.all.incre, get(df.name)$area)
  karea.all.incre[is.na(karea.all.incre)] = 0
}

#Make a long string of all area benefit
area.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  area.all.incre <- c(area.all.incre, get(df.name)$area)
  area.all.incre[is.na(area.all.incre)] = 0
}

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}

```
Set up and run the optimisation (to select priority planning units (LGA's))
```{r, results = FALSE}
model <- list()
#model$A <- matrix(c(data_frame_test$npv), nrow=1)
#nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b)
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')

params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)

print('Solution:')
print(result$objval)
print(result$x)
save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))

```
###Export the results
```{r, results = FALSE}
#Load in base shp file for the planning units
shp.pu <- readOGR("./preprocessing/LGA_study_region_clip_project.shp")

###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#Do the same for conservation benefit
consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(pu.df$LGA)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results
make.maps(outfoldermaps, scen)
exp.vals(outfoldervals, scen)
```

##Approach 2 - Landholder informed cycling through the budgets
```{r, include=FALSE}
#If not already loaded, need this for the make maps function
shp.pu <- readOGR("./preprocessing/LGA_study_region_clip_project.shp")

scen <- "approach2"
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t0", "MeanAdopt", "MeanWTA.tot", "t0.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

#In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
min(cost$Approx_tot_investment)
df$npv <- 1126260

#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "./preprocessing/par/"
# List all files in the folder
files <- list.files("./preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)
#Run  the simulations
df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))
df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

#Add se and sd values
llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))

#Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
#y is the number of increments, 65 increments equates to roughly increments of $1,000,000 

y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y

#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}

#Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes
##Create a new dataframe which has all puid's, so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  # df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  # colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  # df_new <- properties(df1, sim)  
  # assign(paste0("df_new", i), df_new)
  # merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  # assign(paste0("df_new", i), merged)
  # assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  # split.df1 <- split(df1, df$puid)
  # properties.par(split.df1, sim)
  # ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  # ll <- ll[1:length(ll)-1]
  # file.remove(ll)
  # load(paste0(pt, "df_final93.RData"))
  # df_new <- df_final
  # assign(paste0("df_new", i), df_new)
  # merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  # assign(paste0("df_new", i), merged)
  # assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
  # 
  # 
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))
  [rowSums(get(paste0("df_new", i))[])>0,])
  
}
###Set up structures for the optimisation
#Create matrix for constraint that says only 1 budget can be allocated per LGA
#Create matrix where nrow and ncol = no. planning units
#df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=nrow(df_new33),ncol=nrow(df_new33))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
m <- rbind(pu_matrix, npv.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

#Make a long string of koala area
karea.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  karea.all.incre <- c(karea.all.incre, get(df.name)$area)
  karea.all.incre[is.na(karea.all.incre)] = 0
}

#Make a long string of all conservation benefit
cons.all.incre <- df_new0$cons.benefit
for (i in 1:y){
  df.name <- paste0("df_new", i)
  cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
  cons.all.incre[is.na(cons.all.incre)] = 0
}

#Make a long string of all area benefit
area.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  area.all.incre <- c(area.all.incre, get(df.name)$area)
  area.all.incre[is.na(area.all.incre)] = 0
}

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}


for (b in b.vec[1:10]){

#Set up and run the optimisation (to select priority planning units (LGA's))
model <- list()
#model$A <- matrix(c(data_frame_test$npv), nrow=1)
#nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b)
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')

params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)

print('Solution:')
print(result$objval)
print(result$x)
#save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))
save(result, file = paste0(outfolder, "./", scen, "_", b, ".RData"))
}


#Export the results but using Approach 4 conservation and area values - budget matrix stays the same. 
for (b in b.vec[1:10]){
load(paste0(outfolder, "./", scen, "_", b, ".RData"))
#load("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/scenario2_101500000.RData")
###Export the results
###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# load("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/budget.matrix_approach4.RData")
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#Do the same for conservation benefit
load("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/consben.matrix_approach4.RData")
cons.all.incre <- c(consben.matrix)
#consben.matrix <- matrix(cons.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
load("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/area.matrix_approach4.RData")
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results

make.maps(outfoldermaps, scen)
exp.vals(outfoldervals, scen)
}
```




##Approach 1_v2 - Agnostic approach () cycling through the budgets
```{r, include=FALSE}
#If not already loaded, need this for the make maps function
shp.pu <- readOGR("./preprocessing/LGA_study_region_clip_project.shp")
scen <- "approach1"

df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "LValHa", "t0", "area")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "cost", "cons.benefit", "area")

#In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
df$npv <- min(cost$Approx_tot_investment)
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y

#Add new NPV values to the dataframe
df$npv0 <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}
  #Create empty place to save result of the optimisations
  #my_dataframe <- data.frame(matrix(ncol = y+1))
  cons.all.incre <- c()
  #i <- 108012380   
  for (i in unique(df$puid)){
    #To keep track of where it is up to
    print(paste0("Planning_unit_", i))
    
    #Set up dataframes
    #Make a subset of the dataframe which is only data for the respective LGA
    df.LGA <- df[which(df$puid == paste0(i)),]
    #Create empty place to save result of the simulations
    consresult <- c() 
    # List of column names representing npv values
    npv_columns <- colnames(df)[grep("^npv\\d+", colnames(df))]
    #col_name <- "npv1"
    for(col_name in npv_columns) {  
    
    npv_values <- df[[col_name]]
      
    #Set up and run the optimisation (to select priority planning units (LGA's))
    model <- list()
    #model$A <- matrix(c(data_frame_test$npv), nrow=1)
    #nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
    model$A <- matrix(c(df.LGA$cost), nrow=1, byrow=T)
    model$obj        <- df.LGA$cons.benefit
    model$modelsense <- 'max'
    model$rhs        <- unique(npv_values)
    #model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
    model$vtype      <- c('B')

    params <- list(OutputFlag=0)
    #Run
    result <- gurobi(model, params)
    # print('Solution:')
    # print(result$objval)
    # print(result$x)
    
    ##Need summed consben for each LGA under each increment. 
    consben <- sum(result$x*df.LGA$cons.benefit)
    consresult <- c(consresult, consben)*100
    
    }
    # Assign the values of consresult to the new row
    #my_dataframe <- rbind(my_dataframe, consresult)
    cons.all.incre <- c(cons.all.incre, consresult)
  }
  
###Set up other structures for the optimisation
#Create matrix for constraint that says only 1 budget can be allocated per LGA
#Create matrix where nrow and ncol = no. planning units
#df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=length(unique(df$puid)),ncol=length(unique(df$puid)))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))

#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- rep(unique(df$npv0), 93)
npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
for (i in 1:y){
  df.name <- paste0("npv", i)
  x <- rep(unique(df[, df.name]), 93)
  npv.all.incre <- c(npv.all.incre, x)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
m <- rbind(pu_matrix, npv.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

for (b in b.vec[1:10]){
#Set up and run the optimisation (to select priority planning units (LGA's))
model <- list()
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b)
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)
print('Solution:')
print(result$objval)
print(result$x)
save(result, file = paste0(outfolder, "./", scen, "_", b, ".RData"))

}

#Next, we need to generate SD, SE values

#Using these outputs we then need to calculate what we would actually get if we actually invested this money in tenders in these regions
#To do this we need to run the simulation from approach 2
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t0", "MeanAdopt", "MeanWTA.tot", "t0.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "./preprocessing/par/"

#Run through the first of simulations - this is for the first npv increment
#Clean out the paralell processing folder
# List all files in the folder
files <- list.files("./preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)
#Run  the simulations
df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))
df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))

# Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
# y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
min(cost$Approx_tot_investment)
df$npv <- 1126260
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}

##Create a new dataframe which has all puid's (LGAs), so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
}

#Create structures for calculating benefits
# npv.all.incre <- df_new0$npv
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
#   #Make the cost of the NA values so high that they would never be selected
#   npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
# }


#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- rep(unique(df$npv.min), 93)
npv.all.incre[is.na(npv.all.incre)] = 0
for (i in 1:y){
  df.name <- paste0("npv", i)
  x <- rep(unique(df[, df.name]), 93)
  npv.all.incre <- c(npv.all.incre, x)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 0
}


#Make a long string of all conservation benefit

# cons.all.incre <- df_new0$cons.benefit
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
#   cons.all.incre[is.na(cons.all.incre)] = 0
# }

#Make a long string of koala area (in this current formulation this is just property area)
# karea.all.incre <- df_new0$area
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   karea.all.incre <- c(karea.all.incre, get(df.name)$area)
#   karea.all.incre[is.na(karea.all.incre)] = 0
# }

#Make a long string of all area benefit
# area.all.incre <- df_new0$area
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   area.all.incre <- c(area.all.incre, get(df.name)$area)
#   area.all.incre[is.na(area.all.incre)] = 0
# }

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}

#Now we need to call in the results files for approach 1 and calculate the benefits for each based on approach 4 outcomes
#First create a solutions matrix to show which LGA was selected with which budget increment
for (b in b.vec[1:10]){
load(paste0(outfolder, "./", scen, "_", b, ".RData"))
solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- (budget.sol/b)*100

#Do the same for conservation benefit
load("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/consben.matrix_approach4.RData")
cons.all.incre <- c(consben.matrix)
consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(pu.df$LGA)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
load("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/area.matrix_approach4.RData")
area.all.incre <- c(consben.matrix)
karea.all.incre <- area.all.incre
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results
make.maps(outfoldermaps, scen)
exp.vals(outfoldervals, scen)
}

```

##Approach 3_v2 - Climate informed approach (Approach 3_v2) cycling through the budgets
```{r, include=FALSE}
#If not already loaded, need this for the make maps function
shp.pu <- readOGR("./preprocessing/LGA_study_region_clip_project.shp")
scen <- "approach3"

df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "LValHa", "t7", "area")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "cost", "cons.benefit", "area")

#In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
df$npv <- min(cost$Approx_tot_investment)
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y

#Add new NPV values to the dataframe
df$npv0 <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}
  #Create empty place to save result of the optimisations
  #my_dataframe <- data.frame(matrix(ncol = y+1))
  cons.all.incre <- c()
  #i <- 108012380   
  for (i in unique(df$puid)){
    #To keep track of where it is up to
    print(paste0("Planning_unit_", i))
    
    #Set up dataframes
    #Make a subset of the dataframe which is only data for the respective LGA
    df.LGA <- df[which(df$puid == paste0(i)),]
    #Create empty place to save result of the simulations
    consresult <- c() 
    # List of column names representing npv values
    npv_columns <- colnames(df)[grep("^npv\\d+", colnames(df))]
    #col_name <- "npv1"
    for(col_name in npv_columns) {  
    
    npv_values <- df[[col_name]]
      
    #Set up and run the optimisation (to select priority planning units (LGA's))
    model <- list()
    #model$A <- matrix(c(data_frame_test$npv), nrow=1)
    #nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
    model$A <- matrix(c(df.LGA$cost), nrow=1, byrow=T)
    model$obj        <- df.LGA$cons.benefit
    model$modelsense <- 'max'
    model$rhs        <- unique(npv_values)
    #model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
    model$vtype      <- c('B')

    params <- list(OutputFlag=0)
    #Run
    result <- gurobi(model, params)
    # print('Solution:')
    # print(result$objval)
    # print(result$x)
    
    ##Need summed consben for each LGA under each increment. 
    consben <- sum(result$x*df.LGA$cons.benefit)
    consresult <- c(consresult, consben)*100
    
    }
    # Assign the values of consresult to the new row
    #my_dataframe <- rbind(my_dataframe, consresult)
    cons.all.incre <- c(cons.all.incre, consresult)
  }
  
###Set up other structures for the optimisation
#Create matrix for constraint that says only 1 budget can be allocated per LGA
#Create matrix where nrow and ncol = no. planning units
#df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=length(unique(df$puid)),ncol=length(unique(df$puid)))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))

#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- rep(unique(df$npv0), 93)
npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
for (i in 1:y){
  df.name <- paste0("npv", i)
  x <- rep(unique(df[, df.name]), 93)
  npv.all.incre <- c(npv.all.incre, x)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
m <- rbind(pu_matrix, npv.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

for (b in b.vec[1:10]){

#Set up and run the optimisation (to select priority planning units (LGA's))
model <- list()
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b)
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)
print('Solution:')
print(result$objval)
print(result$x)
save(result, file = paste0(outfolder, "./", scen, "_", b, ".RData"))

}

#Using these outputs we then need to calculate what we would actually get if we actually invested this money in tenders in these regions
#To do this we need to run the simulation from approach 2
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t7", "MeanAdopt", "MeanWTA.tot", "t7.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "./preprocessing/par/"

#Run through the first of simulations - this is for the first npv increment
#Clean out the paralell processing folder
# List all files in the folder
files <- list.files("./preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)
#Run  the simulations
df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))
df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))

# Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
# y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}

##Create a new dataframe which has all puid's (LGAs), so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
}


#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- rep(unique(df$npv.min), 93)
#npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
for (i in 1:y){
  df.name <- paste0("npv", i)
  x <- rep(unique(df[, df.name]), 93)
  npv.all.incre <- c(npv.all.incre, x)
  #Make the cost of the NA values so high that they would never be selected
  #npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}


# #Make a long string of all conservation benefit
# cons.all.incre <- df_new0$cons.benefit
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
#   cons.all.incre[is.na(cons.all.incre)] = 0
# }
# 
# #Make a long string of koala area (in this current formulation this is just property area)
# karea.all.incre <- df_new0$area
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   karea.all.incre <- c(karea.all.incre, get(df.name)$area)
#   karea.all.incre[is.na(karea.all.incre)] = 0
# }
# 
# #Make a long string of all area benefit
# area.all.incre <- df_new0$area
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   area.all.incre <- c(area.all.incre, get(df.name)$area)
#   area.all.incre[is.na(area.all.incre)] = 0
# }

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}



#THEN WHAT WE NEED TO DO IS CALL IN EACH OF THE RESULT FILES FOR APPROACH 1 AND CALCULATE THE BENEFTS/EXPORT MAPS FOR EACH
###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
for (b in b.vec[1:10]){
load(paste0(outfolder, "./", scen, "_", b, ".RData"))
solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- (budget.sol/b)*100
#Do the same for conservation benefit

load("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/consben.matrix_approach4.RData")
cons.all.incre <- c(consben.matrix)
consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(pu.df$LGA)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
area.all.incre <- c(consben.matrix)
karea.all.incre <- area.all.incre
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results
#make.maps(outfoldermaps, scen)
make.maps(outfoldermaps, scen)
exp.vals(outfoldervals, scen)
}






# for (b in b.vec[1:10]){
# load(paste0(outfolder, "./", scen, "_", b, ".RData"))
# solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# #FOR HEAT MAPS
# #Then put values to this solutions matrix so we can visualise the selected budget amounts
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol <- rowSums(solutions.budget.matrix)
# #Change budget.sol to proportions instead of exact values
# budget.sol.prop <- (budget.sol/b)*100
# 
# #Do the same for conservation benefit
# load("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/consben.matrix_approach4.RData")
# cons.all.incre <- c(consben.matrix)
# consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(pu.df$LGA)))
# solutions.consben.matrix <- solutions*consben.matrix
# consben.sol <- rowSums(solutions.consben.matrix)
# 
# #And make one from consben/area
# load("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/area.matrix_approach4.RData")
# area.all.incre <- c(consben.matrix)
# karea.all.incre <- area.all.incre
# area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
# solutions.consben.area.matrix <- solutions*area.matrix
# solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
# consben.area.sol <- rowSums(solutions.consben.area.matrix)
# 
# #Generate the results
# make.maps(outfoldermaps, scen)
# exp.vals(outfoldervals, scen)
# 
# }

```



































##19 priority areas only, using Approach 4
```{r}
#Set up dataframe for appropriate scenario
#Here we start with scenario 2 (the scenario that includes both conservation objectives and bidding behaviour, or the "landholder informed" approach). In this scenario we are also using admin.mean (which is the average admin cost across all previous tenders). We allocate the same amount for each tender. 
scen <- "19areas"
df <- df.org[c("Invest_PPA", "NewPropID", "npv.mean", "admin.mean", "rank.t7", "MeanAdopt", "MeanWTA.tot", "t7.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

df <- df[complete.cases(df$puid), ]

#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
```
In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
```{r, include=FALSE}
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
min(cost$Approx_tot_investment)
df$npv <- 1126260
```
Run through the first of simulations - this is for the first npv increment
```{r, results = FALSE, include=FALSE}
#Clean out the paralell processing folder
# List all files in the folder
files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)

df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final19.RData"))
df_new0 <- df_final
#df_new0 <- df_new0[rowSums(df_new0[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- mixedsort(llse)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_19_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- mixedsort(llsd)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_19_sd.csv"))

```
Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
```{r}
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}
```
Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes
```{r, results = FALSE, include=FALSE}
##Create a new dataframe which has all puid's, so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- mixedsort(ll)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final19.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- mixedsort(llse)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_19_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- mixedsort(llsd)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_19_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  #assign(paste0("df_new", i), get(paste0("df_new", i))[complete.cases(get(paste0("df_new", i))), ])
}
```
###Set up structures for the optimisation
Create matrix for constraint that says only 1 budget can be allocated per LGA
```{r}
#Create matrix where nrow and ncol = no. planning units
#df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=length(unique(df$puid)),ncol=length(unique(df$puid)))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
m <- rbind(pu_matrix, npv.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

#Make a long string of all conservation benefit
cons.all.incre <- df_new0$cons.benefit
for (i in 1:y){
  df.name <- paste0("df_new", i)
  cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
  cons.all.incre[is.na(cons.all.incre)] = 0
}

#Make a long string of koala area
karea.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  karea.all.incre <- c(karea.all.incre, get(df.name)$area)
  karea.all.incre[is.na(karea.all.incre)] = 0
}

#Make a long string of all area benefit
area.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  area.all.incre <- c(area.all.incre, get(df.name)$area)
  area.all.incre[is.na(area.all.incre)] = 0
}

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}

```
Set up and run the optimisation (to select priority planning units (LGA's))
```{r, results = FALSE}
model <- list()
#model$A <- matrix(c(data_frame_test$npv), nrow=1)
#nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b)
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')

params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)

print('Solution:')
print(result$objval)
print(result$x)
save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))

#Export the results
#Load in base shp file for the planning units
study_region_outline <- readOGR("./preprocessing/study_region_outline.shp")
crs <- proj4string(study_region_outline)
shp.pu <- readOGR("./preprocessing/19_areas/19_only.shp")
shp.pu <- spTransform(shp.pu, crs)


#shp.pu <- readOGR("E:/Linkage/DSF code/private_land_conservation_DSF/raw_data/LGAs_study_region_clip.shp")

###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
solutions <- matrix(result$x, nrow=length(unique(df$puid)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(df$puid)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#Do the same for conservation benefit
consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(df$puid)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(df$puid)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results
  
make.maps.19areas(outfoldermaps, scen)
exp.vals.19areas(outfoldervals, scen)
```








##Figure 5 - Benefit over budget plot
```{r, include=FALSE}
files <- list.files("./outputs_v16/vals_v16/", pattern = "approach1_budget+", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.approach1 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("./outputs_v16/vals_v16/", pattern = "approach2_budget", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.approach2 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("./outputs_v16/vals_v16/", pattern = "approach3_budget", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.approach3 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("./outputs_v16/vals_v16/", pattern = "approach4_budget+", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.approach4 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

###We need to transform the values so Distance from the optimal solution is the value of the solution 
# distances_approach1 <- sqrt((all.consben.approach1 - all.consben.approach3)^2)
# distances_approach2 <- sqrt((all.consben.approach2 - all.consben.approach4)^2)
# all.consben.approach1.trans <- all.consben.approach3-distances_approach1
# all.consben.approach2.trans <- all.consben.approach4-distances_approach2

df <- data.frame(rep(b.vec, 4), c(all.consben.approach1, all.consben.approach2, all.consben.approach3, all.consben.approach4), c(rep("Approach1", 10), rep("Approach2", 10), rep("Approach3", 10), rep("Approach4", 10)))
                 
colnames(df) <- c("Budget", "Consben", "Scenario")

df$Scenario <- factor(df$Scenario, levels = c('Approach1', 'Approach2', 'Approach3', 'Approach4'))

df$Budget <- df$Budget/1000000

library(ggplot2)

colors <- c("black", "black", "black", "black")
# Plot the data with custom line types and colors

s <- ggplot(df, aes(x = Budget, y = Consben, group = Scenario, linetype = Scenario, color = `Scenario`)) + 
  geom_line(size = 1) +
  scale_color_manual(values = colors) +
  scale_linetype_manual(values = c("solid", "dashed", "dotted", "twodash")) +  # Specify the line types here
  theme(panel.grid = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"),
        legend.background = element_blank()) +
  xlab("Budget M $AUD") +
  ylab("Summed koala landscape capacity")

ggsave("./outputs_v16/figures/df_lines_cons_incl_test.png", s, width = 10, height = 6)


##Calculating values to report for paper
d1 <- all.consben.approach4/all.consben.approach3
d2 <- all.consben.approach2/all.consben.approach1
d3 <- c(d1, d2)
mean(d3)

```







##Simulation sensitivity analysis --> Scen 2 b <- 20300000
```{r}
sim.vec <- seq(0, 1000, by=50)
```
Set up dataframe for appropriate scenario
Here we start with scenario 2 (the scenario that includes both conservation objectives and bidding behaviour, or the "business as usual" scenario). In this scenario we are also using admin.mean (which is the average admin cost across all previous tenders). We allocate the same amount for each tender. 
```{r}
scen <- "scenario2"
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t0", "MeanAdopt", "MeanWTA.tot", "t0.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
```
In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
```{r, include=FALSE}
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
min(cost$Approx_tot_investment)
df$npv <- 1126260
```
Run through the first of simulations - this is for the first npv increment
```{r, results = FALSE, include=FALSE}
time <- Sys.time()
write.csv(time, file = ("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/time_started.csv"))
df.mean.to.plot <- data.frame()
for (q in sim.vec){
df_new0 <- properties.par(split.df, q)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))

llse <- list.files(path=pt, pattern = '.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_scenario2_20300000_93.csv"))

df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}

##Create a new dataframe which has all puid's, so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, q)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = '.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_scenario2_20300000_93.csv"))
  assign(paste0("se.df", i), se.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
}

se.df.all <- se.df0
for (i in 1:y){
  se.df.name <- paste0("se.df", i)
  se.df.all.incre <- get(se.df.name)
  #Make the cost of the NA values so high that they would never be selected
  se.df.all <- merge(se.df.all, se.df.all.incre, by = "X")
}

se.df.all$testMean <- rowMeans(se.df.all, na.rm=TRUE)
mean <- mean(se.df.all$testMean)
df.mean.se <- data.frame(q, mean)
df.mean.to.plot <- rbind(df.mean.to.plot, df.mean.se)

##WE DON'T NEED THIS BIT FOR THE SE VALUES##
# #Create matrix where nrow and ncol = no. planning units
# #df_new <- df_new[rowSums(df_new[])>0,]
# matrix_data=matrix(0,nrow=length(unique(pu.df$LGA)),ncol=length(unique(pu.df$LGA)))
# # assign value to 1
# diag(matrix_data)=1
# #We need as many replicates as there are cost incremements
# pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
# #Join the NPV data to this matrix, for each cost increment
# #First make a long string of all costs
# #Start with the original
# npv.all.incre <- df_new0$npv
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
#   #Make the cost of the NA values so high that they would never be selected
#   npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
# }
# 
# #Join it to the planning unit matrix
# m <- rbind(pu_matrix, npv.all.incre)
# #Make sparse
# constr_matrix <- drop0(m, tol = 0)
# 
# #Make a long string of all conservation benefit
# cons.all.incre <- df_new0$cons.benefit
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
#   cons.all.incre[is.na(cons.all.incre)] = 0
# }
# 
# #Make a long string of koala area
# karea.all.incre <- df_new0$area
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   karea.all.incre <- c(karea.all.incre, get(df.name)$area)
#   karea.all.incre[is.na(karea.all.incre)] = 0
# }
# 
# #Make a long string of all area benefit
# area.all.incre <- df_new0$area
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   area.all.incre <- c(area.all.incre, get(df.name)$area)
#   area.all.incre[is.na(area.all.incre)] = 0
# }
# 
# model <- list()
# #model$A <- matrix(c(data_frame_test$npv), nrow=1)
# #nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
# model$A <- constr_matrix
# model$obj        <- cons.all.incre
# model$modelsense <- 'max'
# model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b)
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
# model$vtype      <- c('B')
# 
# params <- list(OutputFlag=0)
# 
# #Run
# result <- gurobi(model, params)
# 
# print('Solution:')
# print(result$objval)
# print(result$x)
# save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))
# 
# #Load in base shp file for the planning units
# #shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp")
# shp.pu <- readOGR("E:/Linkage/DSF code/private_land_conservation_DSF/raw_data/LGAs_study_region_clip.shp")
# 
# ###Need to be super careful about indexing here
# #First create a solutions matrix to show which LGA was selected with which budget increment
# solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# #FOR HEAT MAPS
# #Then put values to this solutions matrix so we can visualise the selected budget amounts
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol <- rowSums(solutions.budget.matrix)
# 
# #Do the same for conservation benefit
# consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(pu.df$LGA)))
# solutions.consben.matrix <- solutions*consben.matrix
# consben.sol <- rowSums(solutions.consben.matrix)
# 
# #And make one from consben/area
# area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
# solutions.consben.area.matrix <- solutions*area.matrix
# solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
# consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results
#make.maps(outfoldermaps, scen)
#exp.vals.simtest(outfoldervals, scen)

}

write.csv(df.mean.to.plot, file = paste0(outfoldervals, "./", scen, "_budget_", b, "_sensitivity_analysis.csv"), row.names = TRUE)
se.to.plot <- read_csv("outputs_v12/vals_v12/sensitivity_analysis/scenario2_budget_20300000_sensitivity_analysis_v1.csv")
jpeg(file="D:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/sensitivity_analysis/sensitivity_analysis_v2.jpeg")
plot(se.to.plot$q, se.to.plot$mean, xlab="No. of simulations", ylab="Mean standard error of conservation beneft", pch = 19)
dev.off()

# list_csv_files <- list.files(path = "E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12", pattern = '.csv', full.names=TRUE)
# csvs <- readr::read_csv(list_csv_files, id = "file_name")
# csvs <- as.data.frame(csvs)
# csvs$file_name <- gsub(paste0("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/scenario2_budget_", b), "", csvs$file_name)
# csvs$file_name <- gsub(".csv", "", csvs$file_name)
# 
# if (!dir.exists(paste0(outfoldervals, "/sensitivity_analysis/"))) {
#   dir.create(paste0(outfoldervals, "/sensitivity_analysis/"), recursive = TRUE)
# } else {
#   print("Dir already exists!")
# }
# 
# # save histogram in png format in current directory
# png(file=paste0(outfoldervals, "./sensitivity_analysis/", scen, "_consben_sens_", b, ".png"), width=1000, height=1000)
# x <- as.numeric(csvs$file_name)
# y <- as.numeric(csvs$cons.ben)
# plot(x, y, type = "p", xlab = "no. of simulations", ylab = "conservation benefit")
# dev.off()
# 
# png(file=paste0(outfoldervals, "./sensitivity_analysis/", scen, "_area_sens_", b, ".png"), width=1000, height=1000)
# x <- as.numeric(csvs$file_name)
# y <- as.numeric(csvs$karea)
# plot(x, y, type = "p", xlab = "no. of simulations", ylab = "area")
# dev.off()

time <- Sys.time()
write.csv(time, file = ("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/time_finished.csv"))

```



##Code to tie together all values for SM4
```{r, include=FALSE}
# Get a list of all the CSV files in the folder
files <- list.files("./outputs_v16/vals_v16/", pattern = "*csv", full.names = T, recursive = FALSE)

# Create an empty list to hold the data frames
df.list <- list()

# Loop through the files, read them in, and add them to the list
for (i in 1:length(files)) {
  df.list[[i]] <- read.csv(files[i])
}

# Bind the data frames together into one data frame
combined.df <- do.call(rbind, df.list)
##Add a new column that contains the tranformed values for approach 1 and 2 that are shown in the main plot
# consben.trans <- c(all.consben.approach1.trans, all.consben.approach2.trans, c(rep(0, length(all.consben.approach2.trans)*2)))
# combined.df$consben.trans <- consben.trans

# Replace approach names
combined.df$scen <- str_replace_all(combined.df$scen, "approach1", "Agnostic")
combined.df$scen <- str_replace_all(combined.df$scen, "approach2", "Landholder informed")
combined.df$scen <- str_replace_all(combined.df$scen, "approach3", "Climate change informed")
combined.df$scen <- str_replace_all(combined.df$scen, "approach4", "Integrated")

combined.df$cost <- combined.df$cost/1000000

combined.df$karea <- combined.df$karea /1000000

# Change the column names
colnames(combined.df) <- c("", "Approach", "Cost (million $AUD)", "Conservation benefit", "Area covenanted km2", "Summed probability of a bid", "SD", "SE")

# Select the numeric columns you want to round
numeric_columns <- sapply(combined.df, is.numeric)
# Round the numeric columns to 2 decimal places
combined.df[, numeric_columns] <- round(combined.df[, numeric_columns], 3)

# Print the updated DataFrame
print(combined.df)

write.csv(combined.df, "./outputs_v16/all_solutions.csv")

```


#Old Misc code
##Approach 3 - Cycling through the different budgets and cc scenarios
```{r}
cc.names <- c("CCCMAR1t7", "CCCMAR2t7", "CCCMAR3t7", "CSIROMAR1t7", "CSIROMAR2t7", "CSIROMAR3t7", "ECHAMR1t7", "ECHAMR2t7", "ECHAMR3t7", "MIROCR1t7", "MIROCR2t7", "MIROCR3t7", "t7")

for (cc in cc.names[13:length(cc.names)]) {
for (b in b.vec[1:10]){
scen <- paste0(cc, "approach3")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)
save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))

df$result <- result$x
df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- mixedsort(llse)
llse <- llse[1:length(llse)-1]
file.remove(llse)
file <- list.files(path = pt, pattern = "se.csv$")
se.df_scen1 <- read.csv(paste0(pt, file))
se.df_scen1 <- se.df_scen1[complete.cases(se.df_scen1),]

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- mixedsort(llsd)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
file <- list.files(path = pt, pattern = "sd.csv$")
sd.df_scen1 <- read.csv(paste0(pt, file))
sd.df_scen1 <- sd.df_scen1[complete.cases(sd.df_scen1),]

#Load in base shp file for the planning units
#shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp")
shp.pu <- readOGR("E:/Linkage/DSF code/private_land_conservation_DSF/raw_data/LGAs_study_region_clip.shp")

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
budget.sol <- match_list

#Do the same for conservation benefit
match_values <- c(df_new_scen1$cons.benefit)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
consben.sol <- match_list

#And make one from consben/area
match_values <- c(df_new_scen1$area)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
area.sol <- match_list
consben.area.sol <- consben.sol/area.sol
consben.area.sol[is.na(consben.area.sol)] <- 0

#Generate the results
df.to.merge <- data.frame(puid = unique(pu.df$puid))
make.maps(outfoldermaps, scen)
exp.vals.scen1(outfoldervals, scen)

#Clear the parallel processing folder
# Get the list of files in the directory
files <- list.files(pt)
# Delete all files in the directory
file.remove(paste0(pt, "/", files))
}
}


######Approach 3 - Figure 6 heatmap
#CCCMAR1t7
cc.names <- c("CCCMAR1t7", "CCCMAR2t7", "CCCMAR3t7", "CSIROMAR1t7", "CSIROMAR2t7", "CSIROMAR3t7", "ECHAMR1t7", "ECHAMR2t7", "ECHAMR3t7", "MIROCR1t7", "MIROCR2t7", "MIROCR3t7", "t7")
cc <- cc.names[1]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

#load(paste0("./outputs_v12/CCCMAR3t7_scenario1_101500000.RData"))
#CCCMAR3t7 <- result$x 

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
CCCMAR1t7.scen1.budget.sol <- match_list

#CCMAR2t7
cc <- cc.names[2]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
CCCMAR2t7.scen1.budget.sol <- match_list


#CCCMAR3t7
cc <- cc.names[3]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
CCCMAR3t7.scen1.budget.sol <- match_list

#CSIROMAR1t7
cc <- cc.names[4]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
CSIROMAR1t7.scen1.budget.sol <- match_list

#CSIROMAR2t7
cc <- cc.names[5]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
CSIROMAR2t7.scen1.budget.sol <- match_list

#CSIROMAR3t7
cc <- cc.names[6]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
CSIROMAR3t7.scen1.budget.sol <- match_list

#ECHAMR1t7
cc <- cc.names[7]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
ECHAMR1t7.scen1.budget.sol <- match_list

#ECHAMR2t7 
cc <- cc.names[8]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
ECHAMR2t7.scen1.budget.sol <- match_list

#ECHAMR3t7 
cc <- cc.names[9]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
ECHAMR3t7.scen1.budget.sol <- match_list

#MIROCR1t7
cc <- cc.names[10]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
MIROCR1t7.scen1.budget.sol <- match_list

#MIROCR2t7
cc <- cc.names[11]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
MIROCR2t7.scen1.budget.sol <- match_list

#MIROCR3t7
cc <- cc.names[12]
scen <- paste0(cc, "_scenario1")
df <- df.org[c("LGA", "NewPropID", paste0(cc), "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)

df$result <- result$x

df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
MIROCR3t7.scen1.budget.sol <- match_list


# create folder:
if (!dir.exists(outfoldermaps)){
  dir.create(outfoldermaps, recursive = TRUE)
} else {
  print("Dir already exists!")
}
if (!dir.exists(outfoldervals)){
  dir.create(outfoldervals, recursive = TRUE)
} else {
  print("Dir already exists!")
}

all.mean.scen1 <- (CCCMAR1t7.scen1.budget.sol+CCCMAR2t7.scen1.budget.sol+CCCMAR3t7.scen1.budget.sol+MIROCR1t7.scen1.budget.sol+MIROCR2t7.scen1.budget.sol+MIROCR3t7.scen1.budget.sol+ECHAMR1t7.scen1.budget.sol+ECHAMR2t7.scen1.budget.sol+ECHAMR3t7.scen1.budget.sol+CSIROMAR1t7.scen1.budget.sol+CSIROMAR2t7.scen1.budget.sol+CSIROMAR3t7.scen1.budget.sol)/12

# solutions <- matrix(CCCMAR3t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.CCCMAR3t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(CCCMAR3t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.CCCMAR3t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(CCCMAR2t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.CCCMAR2t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(MIROCR1t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.MIROCR1t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(MIROCR2t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.MIROCR2t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(MIROCR1t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.MIROCR1t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(ECHAMR3t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.ECHAMR3t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(ECHAMR2t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.ECHAMR2t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(ECHAMR1t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.ECHAMR1t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(CSIROMAR3t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.CSIROMAR3t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(CSIROMAR2t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.CSIROMAR2t7 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(CSIROMAR1t7, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.CSIROMAR1t7 <- rowSums(solutions.budget.matrix)
# 
# # solutions <- matrix(cccma_cgcm31, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.cccma_cgcm31 <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(ccsr_miroc32hi, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.ccsr_miroc32hi <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(ccsr_miroc32med, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.ccsr_miroc32med <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(cnrm_cm3, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.cnrm_cm3 <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(csiro_mk30, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.csiro_mk30 <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(gfdl_cm20, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.gfdl_cm20 <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(gfdl_cm21, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.gfdl_cm21 <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(giss_modeleh, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.giss_modeleh <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(giss_modeler, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.giss_modeler <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(iap_fgoals10g, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.iap_fgoals10g <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(inm_cm30, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.inm_cm30 <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(ipsl_cm4, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.ipsl_cm4 <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(mpi_echam5, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.mpi_echam5 <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(mri_cgcm232a, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.mri_cgcm232a <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(ncar_ccsm30, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.ncar_ccsm30 <- rowSums(solutions.budget.matrix)
# # 
# # solutions <- matrix(ncar_pcm1, nrow=length(unique(pu.df$LGA)))
# # binary.sol <- rowSums(solutions)
# # budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# # solutions.budget.matrix <- solutions*budget.matrix
# # budget.sol.ncar_pcm1 <- rowSums(solutions.budget.matrix)
# 
# # all.mean <- (budget.sol.cccma_cgcm31+budget.sol.ccsr_miroc32hi+budget.sol.ccsr_miroc32med+budget.sol.cnrm_cm3+budget.sol.csiro_mk30+budget.sol.gfdl_cm20+budget.sol.gfdl_cm21+budget.sol.giss_modeleh+budget.sol.giss_modeler+budget.sol.iap_fgoals10g+budget.sol.inm_cm30+budget.sol.ipsl_cm4+budget.sol.mpi_echam5+budget.sol.mri_cgcm232a+budget.sol.ncar_ccsm30+budget.sol.ncar_pcm1)/18

a <- unique(pu.df$puid)
#HEATMAP
###For heat map showing selected budget
##Join budget values to shp file
pu.and.budget <- data.frame(a, all.mean.scen1)
colnames(pu.and.budget) <- c("CADID", "mean.all")
shp.pu.joined <- merge(shp.pu, pu.and.budget, by = "CADID", duplicateGeoms = TRUE)
shp.pu.joined[is.na(shp.pu.joined$budget.sol)] <- 0
#Export the map
#Generate results
setwd("E:/Linkage/DSF code/private_land_conservation_DSF/")

png(file=paste0(outfoldermaps, "/cc_mean_budget_approach3.png"), width=1000, height=1000)
par(mar=c(0,0,0,0))
#plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
#plot the polygons without colour
plot(shp.pu.joined)
# Set the palette
p <- colorRampPalette(c("white", "#FBD724", "#F2751B", "#C63E4B", "#8B226A", "#4A126B", "#82206B", "#1D0B45", "#000004"))(128)
palette(p)
# Scale the values to the palette
vals <- shp.pu.joined$mean.all
vals[is.na(vals)] <- 0
cols <- (vals - min(vals))/diff(range(vals))*127+1
plot(shp.pu.joined, col=cols)

#Add a legend
levels <- unique(shp.pu.joined$mean.all)
levels <- round(levels, digits=1)
levels <- sort(levels)
col.levels <- unique(cols)
col.levels <- sort(col.levels)

# add a legend to your map
legend("topright",   # location of legend
       legend = levels, # categories or elements to render in
       # the legend
       fill = col.levels, # color palette to use to fill objects in legend.
       title = "Mean budget allocated $ AUD",
       bty = "n",
       cex = 1.2)
cex <- 1
scaleBar(shp.pu.joined, pos = "bottomleft",   
         cex=1,
         pt.cex = 1.1*cex,
         seg.len=10*cex,
         title.cex=cex,
         outer=FALSE)
#suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
dev.off()



```




















<!-- ##Approach 2 cycling through the different budgets -->
<!-- ```{r, include=FALSE} -->

<!-- for (b in b.vec){ -->
<!-- scen <- "scenario2" -->
<!-- df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank", "MeanAdopt", "MeanWTA.tot", "area", "koala_curr.w")] -->
<!-- colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "koala_curr.w") -->
<!-- #We need to make all conservation values uniform, so we allocate a value of 1 -->
<!-- df$rank <-1 -->
<!-- #Again, use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments -->
<!-- cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv") -->
<!-- min(cost$Approx_tot_investment) -->
<!-- df$npv <- 1126260 -->
<!-- #Run through the first of simulations - this is for the first npv increment -->
<!-- df_new0 <- properties.scen2(df, sim)   -->
<!-- df_new0 <- df_new0[rowSums(df_new0[])>0,] -->
<!-- #Create NPV increments, with the min being the lowest NPV reported and the max being the highest.  -->
<!-- #y is the number of increments, 65 increments equates to roughly increments of $1,000,000  -->
<!-- y <- 33 -->
<!-- min_npv <- min(cost$Approx_tot_investment) -->
<!-- max_npv <- max(cost$Approx_tot_investmen) -->
<!-- incre <- (max_npv-min_npv)/y -->
<!-- #Add new NPV values to the dataframe -->
<!-- df$npv.min <- min_npv -->
<!-- for(i in 1:y) {                                   # Head of for-loop -->
<!--   new <- rep(min_npv, nrow(df))                   # Create data for new column -->
<!--   df[ , ncol(df) + 1] <- new + incre*i            # Append new column -->
<!--   colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name -->
<!-- } -->
<!-- #Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes -->
<!-- ##Create a new dataframe which has all puid's, so that new dataframes can be merged to this -->
<!-- #This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton -->
<!-- #So we are merging everything to the complete set of LGA ids -->
<!-- df.to.merge <- data.frame(puid = unique(df$puid)) -->
<!-- df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE) -->
<!-- df_new0 <- df_new[df_new0$puid !=0,] -->
<!-- #Create a new dataframe for each increment (y above) -->
<!-- for (i in 1:y){ -->
<!--   df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "koala_curr.w")] -->
<!--   colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "koala_curr.w") -->
<!--   df_new <- properties.scen2(df1, sim)   -->
<!--   assign(paste0("df_new", i), df_new) -->
<!--   merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE) -->
<!--   assign(paste0("df_new", i), merged) -->
<!--   assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,]) -->
<!--   assign(paste0("df_new", i), get(paste0("df_new", i))[get(paste0("df_new", i))$puid !=0,]) -->
<!-- } -->
<!-- ###Set up structures for the optimisation -->
<!-- #Create matrix for constraint that says only 1 budget can be allocated per LGA -->
<!-- #Create matrix where nrow and ncol = no. planning units -->
<!-- df_new <- df_new[rowSums(df_new[])>1,] -->
<!-- matrix_data=matrix(0,nrow=nrow(df_new),ncol=nrow(df_new)) -->
<!-- # assign value to 1 -->
<!-- diag(matrix_data)=1 -->
<!-- #We need as many replicates as there are cost incremements -->
<!-- pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE)) -->
<!-- #Join the NPV data to this matrix, for each cost increment -->
<!-- #First make a long string of all costs -->
<!-- #Start with the original -->
<!-- npv.all.incre <- df_new0$npv -->
<!-- for (i in 1:y){ -->
<!--   df.name <- paste0("df_new", i) -->
<!--   npv.all.incre <- c(npv.all.incre, get(df.name)$npv) -->
<!--   #Make the cost of the NA values so high that they would never be selected -->
<!--   npv.all.incre[is.na(npv.all.incre)] = 1000000000000000 -->
<!-- } -->

<!-- #Join it to the planning unit matrix -->
<!-- m <- rbind(pu_matrix, npv.all.incre) -->
<!-- #Make sparse -->
<!-- constr_matrix <- drop0(m, tol = 0) -->

<!-- #Make a long string of all conservation benefit -->
<!-- cons.all.incre <- df_new0$cons.benefit -->
<!-- for (i in 1:y){ -->
<!--   df.name <- paste0("df_new", i) -->
<!--   cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit) -->
<!--   cons.all.incre[is.na(cons.all.incre)] = 0 -->
<!-- } -->

<!-- #And in this case make a long string of all koala benefit -->
<!-- koala.all.incre <- df_new0$koala_curr.w -->
<!-- for (i in 1:y){ -->
<!--   df.name <- paste0("df_new", i) -->
<!--   koala.all.incre <- c(koala.all.incre, get(df.name)$koala_curr.w) -->
<!--   koala.all.incre[is.na(koala.all.incre)] = 0 -->
<!-- } -->


<!-- #Set up and run the optimisation (to select priority planning units (LGA's)) -->
<!-- model <- list() -->
<!-- #model$A <- matrix(c(data_frame_test$npv), nrow=1) -->
<!-- #nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector) -->
<!-- model$A <- constr_matrix -->
<!-- model$obj        <- cons.all.incre -->
<!-- model$modelsense <- 'max' -->
<!-- model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b) -->
<!-- model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<') -->
<!-- model$vtype      <- c('B') -->

<!-- params <- list(OutputFlag=0) -->

<!-- #Run -->
<!-- result <- gurobi(model, params) -->

<!-- print('Solution:') -->
<!-- print(result$objval) -->
<!-- print(result$x) -->
<!-- save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData")) -->

<!-- ###Export the results -->
<!-- #Load in base shp file for the planning units -->
<!-- shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp") -->
<!-- ###Need to be super careful about indexing here -->
<!-- #First create a solutions matrix to show which LGA was selected with which budget increment -->
<!-- solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA))) -->
<!-- binary.sol <- rowSums(solutions) -->
<!-- #FOR HEAT MAPS -->
<!-- #Then put values to this solutions matrix so we can visualise the selected budget amounts -->
<!-- budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA))) -->
<!-- solutions.budget.matrix <- solutions*budget.matrix -->
<!-- budget.sol <- rowSums(solutions.budget.matrix) -->
<!-- #Do the same for conservation benefit -->
<!-- consben.matrix <- matrix(koala.all.incre, nrow=length(unique(pu.df$LGA))) -->
<!-- solutions.consben.matrix <- solutions*consben.matrix -->
<!-- consben.sol <- rowSums(solutions.consben.matrix) -->
<!-- #Generate the results -->
<!-- make.maps(outfoldermaps, scen) -->
<!-- exp.vals2(outfoldervals, scen) -->
<!-- } -->
<!-- ``` -->


<!-- ##Approach 1 -->
<!-- Set up dataframe for appropriate scenario -->
<!-- Next we move onto scenario 1 (the scenario that ignores bidding behaviour and optimises based only on conservation values and land value). In this  -->
<!-- scenario we are also using admin.mean (which is the average admin cost across all previous tenders). We allocate the same amount for each tender.  -->
<!-- ```{r} -->
<!-- scen <- "scenario1" -->
<!-- df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank", "MeanAdopt", "LValHa", "koala_curr", "area")] -->
<!-- colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area") -->
<!-- #We need to make all conservation values uniform, so we allocate a value of 1 -->
<!-- df$prob.property <- 1 -->
<!-- ``` -->
<!-- Again, use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments -->
<!-- ```{r} -->
<!-- cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv") -->
<!-- min(cost$Approx_tot_investment) -->
<!-- df$npv <- 1126260 -->
<!-- ``` -->
<!-- Run through the first of simulations - this is for the first npv increment -->
<!-- ```{r, results = FALSE, include=FALSE} -->
<!-- df_new0 <- properties(df, sim)   -->
<!-- df_new0 <- df_new0[rowSums(df_new0[])>0,] -->
<!-- ``` -->
<!-- Create NPV increments, with the min being the lowest NPV reported and the max being the highest.  -->
<!-- y is the number of increments, 65 increments equates to roughly increments of $1,000,000  -->
<!-- ```{r} -->
<!-- y <- 33 -->
<!-- min_npv <- min(cost$Approx_tot_investment) -->
<!-- max_npv <- max(cost$Approx_tot_investmen) -->
<!-- incre <- (max_npv-min_npv)/y -->
<!-- #Add new NPV values to the dataframe -->
<!-- df$npv.min <- min_npv -->
<!-- for(i in 1:y) {                                   # Head of for-loop -->
<!--   new <- rep(min_npv, nrow(df))                   # Create data for new column -->
<!--   df[ , ncol(df) + 1] <- new + incre*i            # Append new column -->
<!--   colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name -->
<!-- } -->
<!-- ``` -->
<!-- Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes -->
<!-- ```{r, results = FALSE, include=FALSE} -->
<!-- ##Create a new dataframe which has all puid's, so that new dataframes can be merged to this -->
<!-- #This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton -->
<!-- #So we are merging everything to the complete set of LGA ids -->
<!-- df.to.merge <- data.frame(puid = unique(df$puid)) -->
<!-- df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE) -->

<!-- #Create a new dataframe for each increment (y above) -->
<!-- for (i in 1:y){ -->
<!--   df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")] -->
<!--   colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area") -->
<!--   df_new <- properties(df1, sim)   -->
<!--   assign(paste0("df_new", i), df_new) -->
<!--   merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE) -->
<!--   assign(paste0("df_new", i), merged) -->
<!--   assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,]) -->
<!--   assign(paste0("df_new", i), get(paste0("df_new", i))[get(paste0("df_new", i))$puid !=0,]) -->
<!-- } -->
<!-- ``` -->
<!-- Now set up and run the optimisation -->
<!-- ###Set up structures for the optimisation -->
<!-- Create matrix for constraint that says only 1 budget can be allocated per LGA -->
<!-- ```{r} -->
<!-- #Create matrix where nrow and ncol = no. planning units -->
<!-- df_new <- df_new[rowSums(df_new[])>1,] -->
<!-- matrix_data=matrix(0,nrow=nrow(df_new),ncol=nrow(df_new)) -->
<!-- # assign value to 1 -->
<!-- diag(matrix_data)=1 -->
<!-- #We need as many replicates as there are cost incremements -->
<!-- pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE)) -->
<!-- #Join the NPV data to this matrix, for each cost increment -->
<!-- #First make a long string of all costs -->
<!-- #Start with the original -->
<!-- npv.all.incre <- df_new0$npv -->
<!-- for (i in 1:y){ -->
<!--   df.name <- paste0("df_new", i) -->
<!--   npv.all.incre <- c(npv.all.incre, get(df.name)$npv) -->
<!--   #Make the cost of the NA values so high that they would never be selected -->
<!--   npv.all.incre[is.na(npv.all.incre)] = 1000000000000000 -->
<!-- } -->

<!-- #Join it to the planning unit matrix -->
<!-- m <- rbind(pu_matrix, npv.all.incre) -->
<!-- #Make sparse -->
<!-- constr_matrix <- drop0(m, tol = 0) -->

<!-- #Make a long string of all conservation benefit -->
<!-- cons.all.incre <- df_new0$cons.benefit -->
<!-- for (i in 1:y){ -->
<!--   df.name <- paste0("df_new", i) -->
<!--   cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit) -->
<!--   cons.all.incre[is.na(cons.all.incre)] = 0 -->
<!-- } -->

<!-- ``` -->
<!-- Set up and run the optimisation (to select priority planning units (LGA's)) -->
<!-- ```{r, results = FALSE, include=FALSE} -->
<!-- model <- list() -->
<!-- #model$A <- matrix(c(data_frame_test$npv), nrow=1) -->
<!-- #nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector) -->
<!-- model$A <- constr_matrix -->
<!-- model$obj        <- cons.all.incre -->
<!-- model$modelsense <- 'max' -->
<!-- model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b) -->
<!-- model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<') -->
<!-- model$vtype      <- c('B') -->

<!-- params <- list(OutputFlag=0) -->

<!-- #Run -->
<!-- result <- gurobi(model, params) -->

<!-- print('Solution:') -->
<!-- print(result$objval) -->
<!-- print(result$x) -->
<!-- save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData")) -->

<!-- ``` -->
<!-- ###Export the results -->
<!-- ```{r, results = FALSE} -->
<!-- #Load in base shp file for the planning units -->
<!-- shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp") -->
<!-- ###Need to be super careful about indexing here -->
<!-- #First create a solutions matrix to show which LGA was selected with which budget increment -->
<!-- solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA))) -->
<!-- binary.sol <- rowSums(solutions) -->
<!-- #FOR HEAT MAPS -->
<!-- #Then put values to this solutions matrix so we can visualise the selected budget amounts -->
<!-- budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA))) -->
<!-- solutions.budget.matrix <- solutions*budget.matrix -->
<!-- budget.sol <- rowSums(solutions.budget.matrix) -->
<!-- #Do the same for conservation benefit -->
<!-- consben.matrix <- matrix(cons.all.incre, nrow=length(unique(pu.df$LGA))) -->
<!-- solutions.consben.matrix <- solutions*consben.matrix -->
<!-- consben.sol <- rowSums(solutions.consben.matrix) -->

<!-- #And make one from consben/area -->
<!-- area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA))) -->
<!-- solutions.consben.area.matrix <- solutions*area.matrix -->
<!-- solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0 -->
<!-- consben.area.sol <- rowSums(solutions.consben.area.matrix) -->

<!-- #Generate the results -->
<!-- make.maps(outfoldermaps, scen) -->
<!-- exp.vals(outfoldervals, scen) -->
<!-- ``` -->






<!-- ##Approach 1 cycling through different budgets -->
<!-- ```{r, include=FALSE} -->
<!-- for (b in b.vec){ -->
<!-- scen <- "scenario1" -->
<!-- df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank", "MeanAdopt", "LValHa", "koala_curr", "area")] -->
<!-- colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area") -->
<!-- #We need to make all conservation values uniform, so we allocate a value of 1 -->
<!-- df$prob.property <- 1 -->
<!-- #Again, use the minimum npv value (for LGAs), this sets up for the next bit of the code which is #increments -->
<!-- cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv") -->
<!-- min(cost$Approx_tot_investment) -->
<!-- df$npv <- 1126260 -->
<!-- #Run through the first of simulations - this is for the first npv increment -->
<!-- df_new0 <- properties(df, sim)   -->
<!-- df_new0 <- df_new0[rowSums(df_new0[])>0,] -->
<!-- #Create NPV increments, with the min being the lowest NPV reported and the max being the highest.  -->
<!-- #y is the number of increments, 65 increments equates to roughly increments of $1,000,000  -->
<!-- y <- 65 -->
<!-- min_npv <- min(cost$Approx_tot_investment) -->
<!-- max_npv <- max(cost$Approx_tot_investmen) -->
<!-- incre <- (max_npv-min_npv)/y -->
<!-- #Add new NPV values to the dataframe -->
<!-- df$npv.min <- min_npv -->
<!-- for(i in 1:y) {                                   # Head of for-loop -->
<!--   new <- rep(min_npv, nrow(df))                   # Create data for new column -->
<!--   df[ , ncol(df) + 1] <- new + incre*i            # Append new column -->
<!--   colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name -->
<!-- } -->
<!-- #Now we need to run separate simulations for each LGA budget increment - this creates y new #dataframes -->

<!-- ##Create a new dataframe which has all puid's, so that new dataframes can be merged to this -->
<!-- #This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton -->
<!-- #So we are merging everything to the complete set of LGA ids -->
<!-- df.to.merge <- data.frame(puid = unique(df$puid)) -->
<!-- df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE) -->

<!-- #Create a new dataframe for each increment (y above) -->
<!-- for (i in 1:y){ -->
<!--   df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")] -->
<!--   colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area") -->
<!--   df_new <- properties(df1, sim)   -->
<!--   assign(paste0("df_new", i), df_new) -->
<!--   merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE) -->
<!--   assign(paste0("df_new", i), merged) -->
<!--   assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,]) -->
<!--   assign(paste0("df_new", i), get(paste0("df_new", i))[get(paste0("df_new", i))$puid !=0,]) -->
<!-- } -->

<!-- #Now set up and run the optimisation -->
<!-- ###Set up structures for the optimisation -->
<!-- #Create matrix for constraint that says only 1 budget can be allocated per LGA -->
<!-- #Create matrix where nrow and ncol = no. planning units -->
<!-- df_new <- df_new[rowSums(df_new[])>1,] -->
<!-- matrix_data=matrix(0,nrow=nrow(df_new),ncol=nrow(df_new)) -->
<!-- # assign value to 1 -->
<!-- diag(matrix_data)=1 -->
<!-- #We need as many replicates as there are cost incremements -->
<!-- pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE)) -->
<!-- #Join the NPV data to this matrix, for each cost increment -->
<!-- #First make a long string of all costs -->
<!-- #Start with the original -->
<!-- npv.all.incre <- df_new0$npv -->
<!-- for (i in 1:y){ -->
<!--   df.name <- paste0("df_new", i) -->
<!--   npv.all.incre <- c(npv.all.incre, get(df.name)$npv) -->
<!--   #Make the cost of the NA values so high that they would never be selected -->
<!--   npv.all.incre[is.na(npv.all.incre)] = 1000000000000000 -->
<!-- } -->

<!-- #Join it to the planning unit matrix -->
<!-- m <- rbind(pu_matrix, npv.all.incre) -->
<!-- #Make sparse -->
<!-- constr_matrix <- drop0(m, tol = 0) -->

<!-- #Make a long string of all conservation benefit -->
<!-- cons.all.incre <- df_new0$cons.benefit -->
<!-- for (i in 1:y){ -->
<!--   df.name <- paste0("df_new", i) -->
<!--   cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit) -->
<!--   cons.all.incre[is.na(cons.all.incre)] = 0 -->
<!-- } -->

<!-- #Set up and run the optimisation (to select priority planning units (LGA's)) -->
<!-- model <- list() -->
<!-- #model$A <- matrix(c(data_frame_test$npv), nrow=1) -->
<!-- #nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector) -->
<!-- model$A <- constr_matrix -->
<!-- model$obj        <- cons.all.incre -->
<!-- model$modelsense <- 'max' -->
<!-- model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b) -->
<!-- model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<') -->
<!-- model$vtype      <- c('B') -->

<!-- params <- list(OutputFlag=0) -->

<!-- #Run -->
<!-- result <- gurobi(model, params) -->

<!-- print('Solution:') -->
<!-- print(result$objval) -->
<!-- print(result$x) -->
<!-- save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData")) -->

<!-- ###Export the results -->
<!-- #Load in base shp file for the planning units -->
<!-- shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp") -->
<!-- ###Need to be super careful about indexing here -->
<!-- #First create a solutions matrix to show which LGA was selected with which budget increment -->
<!-- solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA))) -->
<!-- binary.sol <- rowSums(solutions) -->
<!-- #FOR HEAT MAPS -->
<!-- #Then put values to this solutions matrix so we can visualise the selected budget amounts -->
<!-- budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA))) -->
<!-- solutions.budget.matrix <- solutions*budget.matrix -->
<!-- budget.sol <- rowSums(solutions.budget.matrix) -->
<!-- #Do the same for conservation benefit -->
<!-- consben.matrix <- matrix(cons.all.incre, nrow=length(unique(pu.df$LGA))) -->
<!-- solutions.consben.matrix <- solutions*consben.matrix -->
<!-- consben.sol <- rowSums(solutions.consben.matrix) -->

<!-- #And make one from consben/area -->
<!-- area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA))) -->
<!-- solutions.consben.area.matrix <- solutions*area.matrix -->
<!-- solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0 -->
<!-- consben.area.sol <- rowSums(solutions.consben.area.matrix) -->

<!-- #Generate the results -->
<!-- make.maps(outfoldermaps, scen) -->
<!-- exp.vals(outfoldervals, scen) -->
<!-- } -->
<!-- ``` -->

SCENARIOS TO INFORM ON NSW KOALA STRATEGY
##Approach 1_v1 - Agnostic single budget 
Set up dataframe for appropriate scenario
Next we move onto scenario 1 (the scenario that reflects a typical conservation plan, ie. max ben, within budget, based on land aquesition). 
```{r}
scen <- "approach1"
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t0", "MeanAdopt", "MeanWTA.tot", "t0", "t0.w", "area.w", "LValHa")]

colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "consben", "consben.w", "area", "cost")
```
Run the optimisation for Scen 1
```{r, results = FALSE, include=FALSE}
model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)
save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))

```
Export the results
```{r}
df$result <- result$x
df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", "rank.t0", "MeanAdopt", "MeanWTA.tot", "t0.w", "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- mixedsort(llse)
llse <- llse[1:length(llse)-1]
file.remove(llse)
file <- list.files(path = pt, pattern = "se.csv$")
se.df_scen1 <- read.csv(paste0(pt, file))
se.df_scen1 <- se.df_scen1[complete.cases(se.df_scen1),]


llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- mixedsort(llsd)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
file <- list.files(path = pt, pattern = "sd.csv$")
sd.df_scen1 <- read.csv(paste0(pt, file))
sd.df_scen1 <- sd.df_scen1[complete.cases(sd.df_scen1),]
```
Export maps and vals part2
```{r, results = FALSE}
#Load in base shp file for the planning units
#shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp")
shp.pu <- readOGR("E:/Linkage/DSF code/private_land_conservation_DSF/raw_data/LGAs_study_region_clip.shp")

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
budget.sol <- match_list
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#Do the same for conservation benefit
match_values <- c(df_new_scen1$cons.benefit)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
consben.sol <- match_list

#And make one from consben/area
match_values <- c(df_new_scen1$area)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
area.sol <- match_list
consben.area.sol <- consben.sol/area.sol
consben.area.sol[is.na(consben.area.sol)] <- 0

#Generate the results
df.to.merge <- data.frame(puid = unique(pu.df$puid))
make.maps(outfoldermaps, scen)
exp.vals.scen1(outfoldervals, scen)
```


##Approach 1_v1 - Cycling through the different budgets
```{r}
for (b in b.vec[1:10]){
scen <- "approach1"
df <- df.org[c("LGA", "NewPropID","t0", "LValHa")]
colnames(df) <- c("puid", "NewPropID", "consben", "cost")

model <- list()
model$obj        <- df$consben
# Define cost constraint
model$A <- matrix(c(df$cost), nrow=1, byrow=T)
model$modelsense <- 'max'
model$rhs        <- b
# model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')
params <- list(OutputFlag=0)
#Run
result <- gurobi(model, params)
# Print results
print('Solution:')
print(result$objval)
print(result)
save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))

df$result <- result$x
df <- subset(df, result == 1)
#df.scen1.agg <- aggregate(x = df[c("consben", "cost", "area")], by = df[c("puid")], FUN = sum)
df.scen1.agg <- aggregate(x = df[c("cost")], by = df[c("puid")], FUN = sum)
# Rename the first column to "puid"
colnames(pu.df)[1] <- "puid"
df_test <- merge(pu.df, df.scen1.agg, by = "puid", all = TRUE)
df_test$cost[is.na(df_test$cost)] <- 0

df_scen1 <- df_test[c("puid", "NewPropID", "cost", "admin.mean", "rank.t0", "MeanAdopt", "MeanWTA.tot", "t0.w", "area.w")]
colnames(df_scen1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

split.df <- split(df_scen1, df_scen1$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
#Run the tender function
properties.par(split.df, sim)

ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
# Sort list in ascending order
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
file <- list.files(path = pt, pattern = "\\.RData$")
load(paste0(pt, file))
df_new_scen1 <- df_final
df_new_scen1 <- df_new_scen1[rowSums(df_new_scen1[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- mixedsort(llse)
llse <- llse[1:length(llse)-1]
file.remove(llse)
file <- list.files(path = pt, pattern = "se.csv$")
se.df_scen1 <- read.csv(paste0(pt, file))
se.df_scen1 <- se.df_scen1[complete.cases(se.df_scen1),]


llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- mixedsort(llsd)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
file <- list.files(path = pt, pattern = "sd.csv$")
sd.df_scen1 <- read.csv(paste0(pt, file))
sd.df_scen1 <- sd.df_scen1[complete.cases(sd.df_scen1),]

#Load in base shp file for the planning units
#shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp")
shp.pu <- readOGR("E:/Linkage/DSF code/private_land_conservation_DSF/raw_data/LGAs_study_region_clip.shp")

list1 <- unique(pu.df$puid)
list2 <- df_new_scen1$puid
binary.sol <- ifelse(list1 %in% list2, 1, 0)

#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
match_values <- c(df_new_scen1$npv)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
budget.sol <- match_list
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#Do the same for conservation benefit
match_values <- c(df_new_scen1$cons.benefit)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
consben.sol <- match_list

#And make one from consben/area
match_values <- c(df_new_scen1$area)
match_list <- match_values[match(list1, list2)]
match_list[is.na(match_list)] <- 0
area.sol <- match_list
consben.area.sol <- consben.sol/area.sol
consben.area.sol[is.na(consben.area.sol)] <- 0

#Generate the results
df.to.merge <- data.frame(puid = unique(pu.df$puid))
make.maps(outfoldermaps, scen)
exp.vals.scen1(outfoldervals, scen)

#Clear the parallel processing folder
# Get the list of files in the directory
files <- list.files(pt)
# Delete all files in the directory
file.remove(paste0(pt, "/", files))
}
```





















##19 priority areas only, using Approach 2, how much would 70km2 cost? 
```{r}
#Set up dataframe for appropriate scenario
#Here we start with scenario 2 (the scenario that includes both conservation objectives and bidding behaviour, or the "landholder informed" approach). In this scenario we are also using admin.mean (which is the average admin cost across all previous tenders). We allocate the same amount for each tender. 
scen <- "19areastotcost"
df <- df.org[c("Invest_PPA", "NewPropID", "npv.mean", "admin.mean", "rank.t0", "MeanAdopt", "MeanWTA.tot", "t0.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

df <- df[complete.cases(df$puid), ]

#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
```
In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
```{r, include=FALSE}
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
min(cost$Approx_tot_investment)
df$npv <- 1126260
```
Run through the first of simulations - this is for the first npv increment
```{r, results = FALSE, include=FALSE}
# List all files in the folder
files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)

df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- mixedsort(ll)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final19.RData"))
df_new0 <- df_final
#df_new0 <- df_new0[rowSums(df_new0[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- mixedsort(llse)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_19_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- mixedsort(llsd)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_19_sd.csv"))

```
Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
```{r}
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}
```
Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes
```{r, results = FALSE, include=FALSE}
##Create a new dataframe which has all puid's, so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  
  # List all files in the folder
  files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par", full.names = TRUE)
  # Delete all files
  sapply(files, unlink)
  
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- mixedsort(ll)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final19.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- mixedsort(llse)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_19_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- mixedsort(llsd)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_19_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  #assign(paste0("df_new", i), get(paste0("df_new", i))[complete.cases(get(paste0("df_new", i))), ])
}
```
###Set up structures for the optimisation
Create matrix for constraint that says only 1 budget can be allocated per LGA
```{r}
#Create matrix where nrow and ncol = no. planning units
#df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=length(unique(df$puid)),ncol=length(unique(df$puid)))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

# #Create area-based constraint matrix
# m <- rbind(pu_matrix, npv.all.incre)
# #Make sparse
# constr_matrix <- drop0(m, tol = 0)

#Make a long string of all conservation benefit divided by bid price
cons.all.incre <- df_new0$cons.benefit/df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  cons.all.incre <- c(cons.all.incre, (get(df.name)$cons.benefit/get(df.name)$npv))
  cons.all.incre[is.na(cons.all.incre)] = 0
}

# cons.all.incre <- df_new0$bid.price
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   cons.all.incre <- c(cons.all.incre, get(df.name)$bid.price)
#   cons.all.incre[is.na(cons.all.incre)] = 0
# }

#Make a long string of koala area
karea.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  karea.all.incre <- c(karea.all.incre, get(df.name)$area)
  karea.all.incre[is.na(karea.all.incre)] = 0
}

#Make a long string of all area benefit
area.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  area.all.incre <- c(area.all.incre, get(df.name)$area)
  area.all.incre[is.na(area.all.incre)] = 0
}

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}

#Create area-based constraint matrix
m <- rbind(pu_matrix, area.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

```
Set up and run the optimisation (to select priority planning units (LGA's))
```{r, results = FALSE}
model <- list()
#model$A <- matrix(c(data_frame_test$npv), nrow=1)
#nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), 70000000)
#70000000
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')

params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)

print('Solution:')
print(result$objval)
print(result$x)
save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))

#Export the results
#Load in base shp file for the planning units
study_region_outline <- readOGR("./preprocessing/study_region_outline.shp")
crs <- proj4string(study_region_outline)
shp.pu <- readOGR("./preprocessing/19_areas/19_only.shp")
shp.pu <- spTransform(shp.pu, crs)


#shp.pu <- readOGR("E:/Linkage/DSF code/private_land_conservation_DSF/raw_data/LGAs_study_region_clip.shp")

###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
solutions <- matrix(result$x, nrow=length(unique(df$puid)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(df$puid)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)

#Do the same for conservation benefit
consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(df$puid)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(df$puid)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results
  
make.maps.19areas(outfoldermaps, scen)
exp.vals.19areas(outfoldervals, scen)
```


##Approach 4 - Maximising for cost efficiency
Set up dataframe for appropriate scenario
Here we start with scenario 2 (the scenario that includes both conservation objectives and landholder preferences, or the "landholder informed" approach). In this scenario we are also using admin.mean (which is the average admin cost across all previous tenders). We allocate the same amount for each tender. 
```{r}
scen <- "approach4_cost_eff"
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t7", "MeanAdopt", "MeanWTA.tot", "t7.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
```
In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
```{r, include=FALSE}
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
min(cost$Approx_tot_investment)
df$npv <- 1126260
```
Run through the first of simulations - this is for the first npv increment
```{r, results = FALSE, include=FALSE}
#Clean out the paralell processing folder
# List all files in the folder
files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)
#Run  the simulations
df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))
df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))

```
Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
```{r}
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}
```
Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes
```{r, results = FALSE, include=FALSE}
##Create a new dataframe which has all puid's (LGAs), so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
}
```
###Set up structures for the optimisation
Create matrix for constraint that says only 1 budget can be allocated per LGA
```{r}
#Create matrix where nrow and ncol = no. planning units
#df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=length(unique(pu.df$LGA)),ncol=length(unique(pu.df$LGA)))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
# m <- rbind(pu_matrix, npv.all.incre)
# #Make sparse
# constr_matrix <- drop0(m, tol = 0)

#Make a long string of all conservation benefit
# cons.all.incre <- df_new0$cons.benefit
# for (i in 1:y){
#   df.name <- paste0("df_new", i)
#   cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
#   cons.all.incre[is.na(cons.all.incre)] = 0
# }

#Make a long string of all conservation benefit divided by bid price
cons.all.incre <- (df_new0$cons.benefit)/df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  cons.all.incre <- c(cons.all.incre, ((get(df.name)$cons.benefit)/get(df.name)$npv))
  cons.all.incre[is.na(cons.all.incre)] = 0
}

#Make a long string of koala area (in this current formulation this is just property area)
karea.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  karea.all.incre <- c(karea.all.incre, get(df.name)$area)
  karea.all.incre[is.na(karea.all.incre)] = 0
}

#Make a long string of all area benefit
area.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  area.all.incre <- c(area.all.incre, get(df.name)$area)
  area.all.incre[is.na(area.all.incre)] = 0
}

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}

#Now needs to be about area
m <- rbind(pu_matrix, area.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

```
Set up and run the optimisation (to select priority planning units (LGA's))
```{r, results = FALSE}
model <- list()
#model$A <- matrix(c(data_frame_test$npv), nrow=1)
#nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), 70000000)
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')

params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)

print('Solution:')
print(result$objval)
print(result$x)
save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))

```
###Export the results
```{r, results = FALSE}
#Load in base shp file for the planning units
shp.pu <- readOGR("./preprocessing/LGA_study_region_clip_project.shp")

###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#Do the same for conservation benefit
consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(pu.df$LGA)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results
make.maps(outfoldermaps, scen)
exp.vals(outfoldervals, scen)
```














POST PROCESSING CODE - TO ORGANISE RESULTS AND MISC CODE
##Approach 2 - Get values for comparison against Approach 4
```{r}
#We need to take the budget that was allocated to each LGA and determine what you would get under Approach 4 conditions
#Set up dataframe for Approach 4, then what we are going to do is take the selected LGA's from the Approach 3 optimisation
#to see what the actual benefits would be, for comparison purposes. 
scen <- "approach4"
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", "rank.t7", "MeanAdopt", "MeanWTA.tot", "t7.w", "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"
```
In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
```{r, include=FALSE}
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
min(cost$Approx_tot_investment)
df$npv <- 1126260
```
Run through the first of simulations - this is for the first npv increment
```{r, results = FALSE, include=FALSE}
#Clean out the paralell processing folder
# List all files in the folder
files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par", full.names = TRUE)
# Delete all files
sapply(files, unlink)
#Run  the simulations
df_new0 <- properties.par(split.df, sim)
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))
df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))

```
Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
```{r}
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}
```
Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes
```{r, results = FALSE, include=FALSE}
##Create a new dataframe which has all puid's (LGAs), so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
}
```
###Set up structures for the optimisation
Create matrix for constraint that says only 1 budget can be allocated per LGA
```{r}
#Create matrix where nrow and ncol = no. planning units
#df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=length(unique(pu.df$LGA)),ncol=length(unique(pu.df$LGA)))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
m <- rbind(pu_matrix, npv.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

#Make a long string of all conservation benefit
cons.all.incre <- df_new0$cons.benefit
for (i in 1:y){
  df.name <- paste0("df_new", i)
  cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
  cons.all.incre[is.na(cons.all.incre)] = 0
}

#Make a long string of koala area (in this current formulation this is just property area)
karea.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  karea.all.incre <- c(karea.all.incre, get(df.name)$area)
  karea.all.incre[is.na(karea.all.incre)] = 0
}

#Make a long string of all area benefit
area.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  area.all.incre <- c(area.all.incre, get(df.name)$area)
  area.all.incre[is.na(area.all.incre)] = 0
}

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}

```

```{r}
scen <- "approach2_vs_4"
pu.df <- df.org

for (b in b.vec){

load(paste0("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v13/approach2_", b, ".RData"))
###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Change budget.sol to proportions instead of exact values
budget.sol.prop <- budget.sol/b*100

#Do the same for conservation benefit
consben.matrix <- matrix(cons.all.incre/1000000, nrow=length(unique(pu.df$LGA)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

exp.vals(outfoldervals, scen)
  
}

```



##Approach 4 (Integrated approach) for all of the climate change scenarios, RCP8.5 for the latest year
Set up dataframe for appropriate scenario
Here we start with scenario 3 (the scenario that includes both conservation objectives and bidding behaviour, or the "complete" scenario). In this 
scenario we are also using admin.mean (which is the average admin cost across all previous tenders). We allocate the same amount for each tender. 
```{r, include=FALSE}
#List the names of the climate 18 scenarios
# cc.names <- c("cccma_cgcm31", "ccsr_miroc32hi", "ccsr_miroc32med", "cnrm_cm3", "csiro_mk30", "gfdl_cm20", "gfdl_cm21", "giss_modeleh", "giss_modeler", "iap_fgoals10g", "inm_cm30", "ipsl_cm4", "mpi_echam5", "mri_cgcm232a", "ncar_ccsm30", "ncar_pcm1", "ukmo_hadcm3", "ukmo_hadgem1")

cc.names <- c("CCCMAR1t7", "CCCMAR2t7", "CCCMAR3t7", "CSIROMAR1t7", "CSIROMAR2t7", "CSIROMAR3t7", "ECHAMR1t7", "ECHAMR2t7", "ECHAMR3t7", "MIROCR1t7", "MIROCR2t7", "MIROCR3t7", "t7")

b <- b.vec[10]

#c <- cc.names[1]
#Run through all CC scenarios
for (cc in cc.names[1:length(cc.names)]){
scen <- paste0(cc)
df <- df.org[c("LGA", "NewPropID", "npv.mean", "admin.mean", paste0("rank.", cc), "MeanAdopt", "MeanWTA.tot", paste0(cc, ".w"), "area.w")]
colnames(df) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")

#In this case we first want to use the minimum npv value (for LGAs), this sets up for the next bit of the code which is increments
cost <- read.csv("./raw_data/bct_cost_data_26_7_22.csv")
min(cost$Approx_tot_investment)
df$npv <- 1126260

#For parallel processing
#Split larger dataframe into list of smaller dataframes (ie. one for each planning unit)
split.df <- split(df, df$puid)
#Need to specify path to parallel processed outputs
pt <- "E:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/par/"

#Run through the first of simulations - this is for the first npv increment
df_new0 <- properties.par(split.df, sim)  
ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
ll <- ll[1:length(ll)-1]
file.remove(ll)
load(paste0(pt, "df_final93.RData"))
df_new0 <- df_final
df_new0 <- df_new0[rowSums(df_new0[])>0,]

#Add se and sd values
llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
llse <- llse[1:length(llse)-1]
file.remove(llse)
se.df0 <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))

llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
llsd <- llsd[1:length(llsd)-1]
file.remove(llsd)
sd.df0 <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))

#Create NPV increments, with the min being the lowest NPV reported and the max being the highest. 
#y is the number of increments, 65 increments equates to roughly increments of $1,000,000 
y <- 33
min_npv <- min(cost$Approx_tot_investment)
max_npv <- max(cost$Approx_tot_investmen)
incre <- (max_npv-min_npv)/y
#Add new NPV values to the dataframe
df$npv.min <- min_npv
for(i in 1:y) {                                   # Head of for-loop
  new <- rep(min_npv, nrow(df))                   # Create data for new column
  df[ , ncol(df) + 1] <- new + incre*i            # Append new column
  colnames(df)[ncol(df)] <- paste0("npv", i)      # Rename column name
}
#Now we need to run separate simulations for each LGA budget increment - this creates y new dataframes
##Create a new dataframe which has all puid's, so that new dataframes can be merged to this
#This ensures that even if an LGA has no successful bids (ie. the bidders are higher than the NPV), we capture that in the optimisiaton
#So we are merging everything to the complete set of LGA ids
df.to.merge <- data.frame(puid = unique(df$puid))
df_new0 <- merge(df.to.merge, df_new0, by = "puid", all = TRUE)

#Create a new dataframe for each increment (y above)
for (i in 1:y){
  # df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area", "koala_area")]
  # colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area", "koala_area")
  # df_new <- properties.par(df1, sim)  
  # assign(paste0("df_new", i), df_new)
  # merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  # assign(paste0("df_new", i), merged)
  # assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
  # 
  # 
  
  df1 <- df[c("puid", "NewPropID", paste0("npv", i), "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")]
  colnames(df1) <- c("puid", "NewPropID", "npv", "admin.cost", "property", "prob.property", "bid.price", "cons.benefit", "area")
  #check this
  split.df1 <- split(df1, df$puid)
  properties.par(split.df1, sim)
  ll <- list.files(path=pt, pattern = '.RData', full.names=TRUE)
  ll <- ll[1:length(ll)-1]
  file.remove(ll)
  load(paste0(pt, "df_final93.RData"))
  
  llse <- list.files(path=pt, pattern = 'se.csv', full.names=TRUE)
  llse <- llse[1:length(llse)-1]
  file.remove(llse)
  se.df <- read.csv(paste0(pt, "SE_", scen, "_", b, "_93_se.csv"))
  assign(paste0("se.df", i), se.df)

  llsd <- list.files(path=pt, pattern = 'sd.csv', full.names=TRUE)
  llsd <- llsd[1:length(llsd)-1]
  file.remove(llsd)
  sd.df <- read.csv(paste0(pt, "SD_", scen, "_", b, "_93_sd.csv"))
  assign(paste0("sd.df", i), sd.df)
  
  df_new <- df_final
  assign(paste0("df_new", i), df_new)
  merged <- merge(df.to.merge, get(paste0("df_new", i)), by = "puid", all = TRUE)
  assign(paste0("df_new", i), merged)
  assign(paste0("df_new", i), get(paste0("df_new", i))[rowSums(get(paste0("df_new", i))[])>0,])
}
#Set up structures for the optimisation
#Create matrix for constraint that says only 1 budget can be allocated per LGA
#Create matrix where nrow and ncol = no. planning units
df_new <- df_new[rowSums(df_new[])>0,]
matrix_data=matrix(0,nrow=nrow(df_new),ncol=nrow(df_new))
# assign value to 1
diag(matrix_data)=1
#We need as many replicates as there are cost incremements
pu_matrix <- do.call(cbind, replicate(y+1,matrix_data, simplify=FALSE))
#Join the NPV data to this matrix, for each cost increment
#First make a long string of all costs
#Start with the original
npv.all.incre <- df_new0$npv
for (i in 1:y){
  df.name <- paste0("df_new", i)
  npv.all.incre <- c(npv.all.incre, get(df.name)$npv)
  #Make the cost of the NA values so high that they would never be selected
  npv.all.incre[is.na(npv.all.incre)] = 1000000000000000
}

#Join it to the planning unit matrix
m <- rbind(pu_matrix, npv.all.incre)
#Make sparse
constr_matrix <- drop0(m, tol = 0)

#Make a long string of koala area
karea.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  karea.all.incre <- c(karea.all.incre, get(df.name)$area)
  karea.all.incre[is.na(karea.all.incre)] = 0
}

#Make a long string of all conservation benefit
cons.all.incre <- df_new0$cons.benefit
for (i in 1:y){
  df.name <- paste0("df_new", i)
  cons.all.incre <- c(cons.all.incre, get(df.name)$cons.benefit)
  cons.all.incre[is.na(cons.all.incre)] = 0
}

#Make a long string of all area benefit
area.all.incre <- df_new0$area
for (i in 1:y){
  df.name <- paste0("df_new", i)
  area.all.incre <- c(area.all.incre, get(df.name)$area)
  area.all.incre[is.na(area.all.incre)] = 0
}

#Make a long string of all SD
sd.all.incre <- sd.df0[1:nrow(sd.df0),2]
for (i in 1:y){
  df.name <- paste0("sd.df", i)
  sd.all.incre <- c(sd.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  sd.all.incre[is.na(sd.all.incre)] = 0
}

#Make a long string of all SE
se.all.incre <- se.df0[1:nrow(se.df0),2]
for (i in 1:y){
  df.name <- paste0("se.df", i)
  se.all.incre <- c(se.all.incre, get(df.name)[1:nrow(get(df.name)),2])
  se.all.incre[is.na(se.all.incre)] = 0
}

#Set up and run the optimisation (to select priority planning units (LGA's))
model <- list()
#model$A <- matrix(c(data_frame_test$npv), nrow=1)
#nrow needs to be the number of planning units/LGA's + 1 (the 1 is the data vector)
model$A <- constr_matrix
model$obj        <- cons.all.incre
model$modelsense <- 'max'
model$rhs        <- c(rep(1, nrow(constr_matrix)-1), b)
model$sense      <- c(rep('<=',nrow(constr_matrix)-1),'<')
model$vtype      <- c('B')

params <- list(OutputFlag=0)

#Run
result <- gurobi(model, params)

print('Solution:')
print(result$objval)
print(result$x)
save(result, file=paste0(outfolder, "./", scen, "_", b, ".RData"))

#Export the results
#Load in base shp file for the planning units
shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp")
###Need to be super careful about indexing here
#First create a solutions matrix to show which LGA was selected with which budget increment
solutions <- matrix(result$x, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
#FOR HEAT MAPS
#Then put values to this solutions matrix so we can visualise the selected budget amounts
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol <- rowSums(solutions.budget.matrix)
#Do the same for conservation benefit
consben.matrix <- matrix(cons.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.consben.matrix <- solutions*consben.matrix
consben.sol <- rowSums(solutions.consben.matrix)

#And make one from consben/area
area.matrix <- matrix(((cons.all.incre/1000000)/(area.all.incre/1000000)), nrow=length(unique(pu.df$LGA)))
solutions.consben.area.matrix <- solutions*area.matrix
solutions.consben.area.matrix[is.nan(solutions.consben.area.matrix)] <- 0
consben.area.sol <- rowSums(solutions.consben.area.matrix)

#Generate the results
make.maps(outfoldermaps, scen)
exp.vals(outfoldervals, scen)

######Print diagnostic plots
shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp")
##Get the summed aggregate of koala habitat in each LGA  
  agg.cons <- aggregate(x = df.org %>% pull(paste0(cc, ".w")), by = list(df.org$LGA), FUN = sum)
  colnames(agg.cons) <- c("CADID", "cc_scen")
  shp.pu.joined <- merge(shp.pu, agg.cons, by = "CADID")
  shp.pu.joined[is.na(shp.pu.joined$cc_scen)] <- 0
  
  #Export the map
  png(file=paste0(outfoldermaps, "./Conservation_benefit_", cc, "_w_.png"), width=1000, height=1000)
  par(mar=c(0,0,0,0))
  #plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
  #plot the polygons without colour
  plot(shp.pu.joined)
  # Set the palette
  p <- colorRampPalette(c("white", "#009933", "#003300"))(128)
  palette(p)       
  # Scale the values to the palette
  vals <- shp.pu.joined$cc_scen
  cols <- (vals - min(vals))/diff(range(vals))*127+1
  plot(shp.pu.joined, col=cols)

  #Add a legend
  levels <- unique(shp.pu.joined$cc_scen)
  levels <- round(levels, digits=1)
  levels <- sort(levels)
  col.levels <- unique(cols)
  col.levels <- sort(col.levels)
  
  
  # add a legend to your map
  legend("topright",   # location of legend
         legend = levels, # categories or elements to render in
         # the legend
         fill = col.levels, # color palette to use to fill objects in legend.
         title = "Suitability weighted koala habitat km2",
         bty = "n",
         cex = 0.7)
  cex <- 1
  scaleBar(shp.pu, pos = "bottomleft",   
           cex=1,
           pt.cex = 1.1*cex,
           seg.len=10*cex,
           title.cex=cex,
           outer=FALSE)
  #suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
  dev.off()
}


###Create map that is the average budget allocated to each LGA across all cc scenarios
# load(paste0("./outputs_v5/cccma_cgcm31_101500000.RData"))
# cccma_cgcm31 <- result$x 
# load(paste0("./outputs_v5/ccsr_miroc32hi_101500000.RData"))
# ccsr_miroc32hi <- result$x 
# load(paste0("./outputs_v5/ccsr_miroc32med_101500000.RData"))
# ccsr_miroc32med <- result$x 
# load(paste0("./outputs_v5/cnrm_cm3_101500000.RData"))
# cnrm_cm3 <- result$x 
# load(paste0("./outputs_v5/csiro_mk30_101500000.RData"))
# csiro_mk30 <- result$x 
# load(paste0("./outputs_v5/gfdl_cm20_101500000.RData"))
# gfdl_cm20 <- result$x 
# load(paste0("./outputs_v5/gfdl_cm21_101500000.RData"))
# gfdl_cm21 <- result$x 
# load(paste0("./outputs_v5/giss_modeleh_101500000.RData"))
# giss_modeleh <- result$x 
# load(paste0("./outputs_v5/giss_modeler_101500000.RData"))
# giss_modeler <- result$x 
# load(paste0("./outputs_v5/iap_fgoals10g_101500000.RData"))
# iap_fgoals10g <- result$x 
# load(paste0("./outputs_v5/inm_cm30_101500000.RData"))
# inm_cm30 <- result$x
# load(paste0("./outputs_v5/ipsl_cm4_101500000.RData"))
# ipsl_cm4 <- result$x
# load(paste0("./outputs_v5/mpi_echam5_101500000.RData"))
# mpi_echam5 <- result$x
# load(paste0("./outputs_v5/mri_cgcm232a_101500000.RData"))
# mri_cgcm232a <- result$x
# load(paste0("./outputs_v5/ncar_ccsm30_101500000.RData"))
# ncar_ccsm30 <- result$x
# load(paste0("./outputs_v5/ncar_pcm1_101500000.RData"))
# ncar_pcm1 <- result$x

load(paste0("./outputs_v12/CCCMAR3t7_101500000.RData"))
CCCMAR3t7 <- result$x 
load(paste0("./outputs_v12/CCCMAR2t7_101500000.RData"))
CCCMAR2t7 <- result$x 
load(paste0("./outputs_v12/CCCMAR1t7_101500000.RData"))
CCCMAR1t7 <- result$x 
load(paste0("./outputs_v12/MIROCR3t7_101500000.RData"))
load(paste0("./outputs_v12/MIROCR3t7_101500000.RData"))
MIROCR3t7 <- result$x 
load(paste0("./outputs_v12/MIROCR2t7_101500000.RData"))
MIROCR2t7 <- result$x 
load(paste0("./outputs_v12/MIROCR1t7_101500000.RData"))
MIROCR1t7 <- result$x 
load(paste0("./outputs_v12/ECHAMR3t7_101500000.RData"))
ECHAMR3t7 <- result$x 
load(paste0("./outputs_v12/ECHAMR2t7_101500000.RData"))
ECHAMR2t7 <- result$x 
load(paste0("./outputs_v12/ECHAMR1t7_101500000.RData"))
ECHAMR1t7 <- result$x 
load(paste0("./outputs_v12/CSIROMAR3t7_101500000.RData"))
CSIROMAR3t7 <- result$x 
load(paste0("./outputs_v12/CSIROMAR2t7_101500000.RData"))
CSIROMAR2t7 <- result$x 
load(paste0("./outputs_v12/CSIROMAR1t7_101500000.RData"))
CSIROMAR1t7 <- result$x 


# create folder:
if (!dir.exists(outfoldermaps)){
  dir.create(outfoldermaps, recursive = TRUE)
} else {
  print("Dir already exists!")
}
if (!dir.exists(outfoldervals)){
  dir.create(outfoldervals, recursive = TRUE)
} else {
  print("Dir already exists!")
}

# npv.all.incre <- c(df_new1$npv, df_new2$npv, df_new3$npv, df_new4$npv, df_new5$npv, df_new6$npv, df_new7$npv, df_new8$npv, df_new9$npv, df_new10$npv, df_new11$npv, df_new12$npv, df_new13$npv, df_new14$npv, df_new15$npv, df_new16$npv, df_new17$npv, df_new18$npv, df_new19$npv, df_new20$npv, df_new21$npv, df_new22$npv, df_new23$np, df_new24$npv, df_new25$npv, df_new26$npv, df_new27$npv, df_new28$npv, df_new29$npv, df_new30$npv, df_new31$npv, df_new32$npv, df_new33$npv)
solutions <- matrix(CCCMAR3t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.CCCMAR3t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(CCCMAR2t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.CCCMAR2t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(CCCMAR1t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.CCCMAR1t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(MIROCR3t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.MIROCR3t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(MIROCR2t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.MIROCR2t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(MIROCR1t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.MIROCR1t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(ECHAMR3t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.ECHAMR3t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(ECHAMR2t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.ECHAMR2t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(ECHAMR1t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.ECHAMR1t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(CSIROMAR3t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.CSIROMAR3t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(CSIROMAR2t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.CSIROMAR2t7 <- rowSums(solutions.budget.matrix)

solutions <- matrix(CSIROMAR1t7, nrow=length(unique(pu.df$LGA)))
binary.sol <- rowSums(solutions)
budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
solutions.budget.matrix <- solutions*budget.matrix
budget.sol.CSIROMAR1t7 <- rowSums(solutions.budget.matrix)

# solutions <- matrix(cccma_cgcm31, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.cccma_cgcm31 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(ccsr_miroc32hi, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.ccsr_miroc32hi <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(ccsr_miroc32med, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.ccsr_miroc32med <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(cnrm_cm3, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.cnrm_cm3 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(csiro_mk30, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.csiro_mk30 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(gfdl_cm20, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.gfdl_cm20 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(gfdl_cm21, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.gfdl_cm21 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(giss_modeleh, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.giss_modeleh <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(giss_modeler, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.giss_modeler <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(iap_fgoals10g, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.iap_fgoals10g <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(inm_cm30, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.inm_cm30 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(ipsl_cm4, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.ipsl_cm4 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(mpi_echam5, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.mpi_echam5 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(mri_cgcm232a, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.mri_cgcm232a <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(ncar_ccsm30, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.ncar_ccsm30 <- rowSums(solutions.budget.matrix)
# 
# solutions <- matrix(ncar_pcm1, nrow=length(unique(pu.df$LGA)))
# binary.sol <- rowSums(solutions)
# budget.matrix <- matrix(npv.all.incre, nrow=length(unique(pu.df$LGA)))
# solutions.budget.matrix <- solutions*budget.matrix
# budget.sol.ncar_pcm1 <- rowSums(solutions.budget.matrix)

# all.mean <- (budget.sol.cccma_cgcm31+budget.sol.ccsr_miroc32hi+budget.sol.ccsr_miroc32med+budget.sol.cnrm_cm3+budget.sol.csiro_mk30+budget.sol.gfdl_cm20+budget.sol.gfdl_cm21+budget.sol.giss_modeleh+budget.sol.giss_modeler+budget.sol.iap_fgoals10g+budget.sol.inm_cm30+budget.sol.ipsl_cm4+budget.sol.mpi_echam5+budget.sol.mri_cgcm232a+budget.sol.ncar_ccsm30+budget.sol.ncar_pcm1)/18


all.mean <- (budget.sol.CCCMAR3t7+budget.sol.CCCMAR2t7+budget.sol.CCCMAR1t7+budget.sol.MIROCR1t7+budget.sol.MIROCR2t7+budget.sol.MIROCR3t7+budget.sol.ECHAMR1t7+budget.sol.ECHAMR2t7+budget.sol.ECHAMR3t7+budget.sol.CSIROMAR1t7+budget.sol.CSIROMAR2t7+budget.sol.CSIROMAR3t7)/12

a <- unique(pu.df$LGA)
#HEATMAP
###For heat map showing selected budget
##Join budget values to shp file
pu.and.budget <- data.frame(a, all.mean)
colnames(pu.and.budget) <- c("CADID", "mean.all")
shp.pu.joined <- merge(shp.pu, pu.and.budget, by = "CADID", duplicateGeoms = TRUE)
shp.pu.joined[is.na(shp.pu.joined$budget.sol)] <- 0
#Export the map
#Generate results
setwd("E:/Linkage/DSF code/private_land_conservation_DSF/")

png(file=paste0(outfoldermaps, "/cc_mean_budget_approach4.png"), width=1000, height=1000)
par(mar=c(0,0,0,0))
#plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
#plot the polygons without colour
plot(shp.pu.joined)
# Set the palette
p <- colorRampPalette(c("white", "#FBD724", "#F2751B", "#C63E4B", "#8B226A", "#4A126B", "#82206B", "#1D0B45", "#000004"))(128)
palette(p)
# Scale the values to the palette
vals <- shp.pu.joined$mean.all
vals[is.na(vals)] <- 0
cols <- (vals - min(vals))/diff(range(vals))*127+1
plot(shp.pu.joined, col=cols)

#Add a legend
levels <- unique(shp.pu.joined$mean.all)
levels <- round(levels, digits=1)
levels <- sort(levels)
col.levels <- unique(cols)
col.levels <- sort(col.levels)

# add a legend to your map
legend("topright",   # location of legend
       legend = levels, # categories or elements to render in
       # the legend
       fill = col.levels, # color palette to use to fill objects in legend.
       title = "Mean budget allocated $ AUD",
       bty = "n",
       cex = 1.2)
cex <- 1
scaleBar(shp.pu.joined, pos = "bottomleft",   
         cex=1,
         pt.cex = 1.1*cex,
         seg.len=10*cex,
         title.cex=cex,
         outer=FALSE)
#suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
dev.off()

```











##Diagnostic plots
```{r, include=FALSE}
shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp")
##Get the summed aggregate of koala habitat in each LGA  
  agg.cons <- aggregate(x = df.org$koala_curr.w, by = list(df.org$LGA), FUN = sum)
  colnames(agg.cons) <- c("CADID", "koala_curr.w")
  shp.pu.joined <- merge(shp.pu, agg.cons, by = "CADID")
  shp.pu.joined[is.na(shp.pu.joined$koala_curr.w)] <- 0
  
  #Export the map
  png(file=paste0(outfoldermaps, "./Conservation_benefit.png"), width=1000, height=1000)
  par(mar=c(0,0,0,0))
  #plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
  #plot the polygons without colour
  plot(shp.pu.joined)
  # Set the palette
  p <- colorRampPalette(c("white", "#009933", "#003300"))(128)
  palette(p)
  # Scale the values to the palette
  vals <- shp.pu.joined$koala_curr.w
  cols <- (vals - min(vals))/diff(range(vals))*127+1
  plot(shp.pu.joined, col=cols)
  
  #Add a legend
  levels <- unique(shp.pu.joined$koala_curr.w)
  levels <- round(levels, digits=1)
  levels <- sort(levels)
  col.levels <- unique(cols)
  col.levels <- sort(col.levels)
  
  # add a legend to your map
  legend("topright",   # location of legend
         legend = levels, # categories or elements to render in
         # the legend
         fill = col.levels, # color palette to use to fill objects in legend.
         title = "Suitability weighted koala habitat km2",
         bty = "n",
         cex = 0.7)
  cex <- 1
  scaleBar(shp.pu, pos = "bottomleft",   
           cex=1,
           pt.cex = 1.1*cex,
           seg.len=10*cex,
           title.cex=cex,
           outer=FALSE)
  #suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
  dev.off()
  
  
###Plot the conservation benefit weighted by proportion that people would covent
  shp.pu <- readOGR("./raw_data/LGAs_study_region_clip.shp")
###Get the summed aggregate of koala habitat in each LGA  
  agg.cons <- aggregate(x = df.org$koala_curr.w*df.org$MeanProp, by = list(df.org$LGA), FUN = sum)
  colnames(agg.cons) <- c("CADID", "koala_curr.w.prop")
  shp.pu.joined <- merge(shp.pu, agg.cons, by = "CADID")
  shp.pu.joined[is.na(shp.pu.joined$koala_curr.w.prop)] <- 0
  
  #Export the map
  png(file=paste0(outfoldermaps, "./Conservation_benefit_prop_covent.png"), width=1000, height=1000)
  par(mar=c(0,0,0,0))
  #plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
  #plot the polygons without colour
  plot(shp.pu.joined)
  # Set the palette
  p <- colorRampPalette(c("white", "#009933", "#003300"))(128)
  palette(p)
  # Scale the values to the palette
  vals <- shp.pu.joined$koala_curr.w.prop
  cols <- (vals - min(vals))/diff(range(vals))*127+1
  plot(shp.pu.joined, col=cols)
  
  #Add a legend
  levels <- unique(shp.pu.joined$koala_curr.w.prop)
  levels <- round(levels, digits=1)
  levels <- sort(levels)
  col.levels <- unique(cols)
  col.levels <- sort(col.levels)
  
  # add a legend to your map
  legend("topright",   # location of legend
         legend = levels, # categories or elements to render in
         # the legend
         fill = col.levels, # color palette to use to fill objects in legend.
         title = "Suitability weighted koala habitat km2",
         bty = "n",
         cex = 0.7)
  cex <- 1
  scaleBar(shp.pu, pos = "bottomleft",   
           cex=1,
           pt.cex = 1.1*cex,
           seg.len=10*cex,
           title.cex=cex,
           outer=FALSE)
  #suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
  dev.off()
  
  

```


##Difference map###
```{r, include=FALSE}
#setwd("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v7/")
#Load in result data
solutions <- read.csv("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v13/vals_v13/approach1_pu_vs_budget_101500000.csv")
#solutions <- matrix(result$x, nrow=length(unique(pu.df$puid)))
# Iterate over each value in the second column
for (i in 1:nrow(solutions)) {
  # Check if the value is greater than 0
  if (solutions[i, "budget.sol"] > 0) {
    # Set the value to 1
    solutions[i, "budget.sol"] <- 1
  }
}

binary.sol.1 <- solutions
binary.sol.1 <- binary.sol.1[2:ncol(binary.sol.1)]
colnames(binary.sol.1)[1] <- "df_new.puid"
#binary.sol.1 <- rowSums(solutions)
#binary.sol.1 <- data.frame(df_new$puid, binary.sol.1)

#scen <- "scenario2"
#load(paste0(scen, ".RData"))
load("outputs_v13/approach2_101500000.RData")
solutions <- matrix(result$x, nrow=length(unique(pu.df$puid)))
binary.sol.2 <- rowSums(solutions)
binary.sol.2 <- data.frame(df_new$puid, binary.sol.2)

sols <- merge(binary.sol.1, binary.sol.2, by = "df_new.puid")
sols$rowsum <- sols$budget.sol+sols$binary.sol.2
#test <- binary.sol.1+binary.sol.2
common <- sols[sols$both == '2',]

cols <- c("CADID","scen1","scen2","both")
colnames(sols) <- cols

png(file=paste0(outfoldermaps, "/diff_scen_1_2.png"), width=1000, height=1000)
par(mar=c(0,0,0,0))
#plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
plot(shp.pu)
merge <- merge(shp.pu, sols)
merge[is.na(merge$scen1)] <- 0
merge[is.na(merge$scen2)] <- 0
merge[is.na(merge$both)] <- 0


shp.onlyscen1 <- merge[merge$scen1 == "1",]
plot(shp.onlyscen1, col = "mistyrose2", add = TRUE)
shp.onlyscen2 <- merge[merge$scen2 == "1",]
plot(shp.onlyscen2, col = "slategray2", add = TRUE)
shp.common <- shp.pu[shp.pu$CADID %in% c(common$CADID),]
plot(shp.common, col = "seagreen3", add = TRUE)

# scaleBar(merge, pos = "bottomleft",   
#          cex=1,
#          pt.cex = 1.1*cex,
#          seg.len=10*cex,
#          title.cex=cex,
#          outer=FALSE)
# #suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
dev.off()
```




##Supporting maps
```{r, include=FALSE}
  ###For heat map showing #1 landscape capacity/unimproved land value
  df.org$con_by_unimpvalue <- df.org$t0/df.org$LValHa

  # Aggregate values by puid
  agg.df.org <- aggregate(con_by_unimpvalue ~ LGA, data = df.org, FUN = mean)
  agg.df.org$con_by_unimpvalue <- log(agg.df.org$con_by_unimpvalue)
  #agg.df.org$con_by_unimpvalue <- scale(agg.df.org$con_by_unimpvalue)
  
  ##Join budget values to shp file
  #pu.and.consben <- data.frame(df.to.merge$puid, consben.sol)
  colnames(agg.df.org) <- c("CADID", "con_by_unimpvalue")
  shp.pu.joined <- merge(shp.pu, agg.df.org, by = "CADID")
  shp.pu.joined[is.na(shp.pu.joined$con_by_unimpvalue)] <- 0
  #Export the map
  png(file=paste0(outfoldermaps, "./SM_con_by_unimpvalue_heatmap.png"),  width=1000, height=1000)
  par(mar=c(0,0,0,0))
  #plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
  #plot the polygons without colour
  plot(shp.pu.joined)
  # Set the palette
  p <- colorRampPalette(c("#FBFBB3", "#FF946E", "#D2426E", "#902890", "#46177F","#04030B"))(1000)
  # Scale the values to the palette
  vals <- shp.pu.joined$con_by_unimpvalue
  cols <- (vals - min(vals))/diff(range(vals))*999+1
  plot(shp.pu.joined, col=cols)
  
  #Add a legend
  levels <- unique(shp.pu.joined$con_by_unimpvalue)
  levels <- round(levels, digits=8)
  levels <- sort(levels)
  col.levels <- unique(cols)
  col.levels <- sort(col.levels)
  
  # add a legend to your map
  # legend("right",   # location of legend
  #        legend = levels, # categories or elements to render in
  #        # the legend
  #        fill = col.levels, # color palette to use to fill objects in legend.
  #        # title = "Suitability weighted koala
  #        # habitat km2",
  #        title = "Summed suitability",
  #        bty = "n",
  #        cex = 1.2)
  # cex <- 1
  scaleBar(shp.pu, pos = "bottomleft",
           cex=1,
           pt.cex = 1.1*cex,
           seg.len=10*cex,
           title.cex=cex,
           outer=FALSE)
  suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
  dev.off()
  
  
  ###For heat map showing #2  landscape capacity * probability consider covenant / bid price
  df.org$con_by_unimpvalue <- (df.org$t0*df.org$MeanAdopt)/df.org$MeanWTA.tot

  # Aggregate values by puid
  agg.df.org <- aggregate(con_by_unimpvalue ~ LGA, data = df.org, FUN = mean)
  #agg.df.org$con_by_unimpvalue <- log(agg.df.org$con_by_unimpvalue)
  #agg.df.org$con_by_unimpvalue <- scale(agg.df.org$con_by_unimpvalue)
  
  ##Join budget values to shp file
  #pu.and.consben <- data.frame(df.to.merge$puid, consben.sol)
  colnames(agg.df.org) <- c("CADID", "con_by_unimpvalue")
  shp.pu.joined <- merge(shp.pu, agg.df.org, by = "CADID")
  shp.pu.joined[is.na(shp.pu.joined$con_by_unimpvalue)] <- 0
  #Export the map
  png(file=paste0(outfoldermaps, "./SM_con_by_adopt_bid_heatmap.png"),  width=1000, height=1000)
  par(mar=c(0,0,0,0))
  #plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
  #plot the polygons without colour
  plot(shp.pu.joined)
  # Set the palette
  p <- colorRampPalette(c("#FBFBB3", "#FF946E", "#D2426E", "#902890", "#46177F","#04030B"))(1000)
  palette(p)
  # Scale the values to the palette
  vals <- shp.pu.joined$con_by_unimpvalue
  cols <- (vals - min(vals))/diff(range(vals))*999+1
  plot(shp.pu.joined, col=cols)
  
  #Add a legend
  levels <- unique(shp.pu.joined$con_by_unimpvalue)
  levels <- round(levels, digits=8)
  levels <- sort(levels)
  col.levels <- unique(cols)
  col.levels <- sort(col.levels)
  
  # add a legend to your map
  # legend("right",   # location of legend
  #        legend = levels, # categories or elements to render in
  #        # the legend
  #        fill = col.levels, # color palette to use to fill objects in legend.
  #        # title = "Suitability weighted koala
  #        # habitat km2",
  #        title = "Summed suitability",
  #        bty = "n",
  #        cex = 1.2)
  # cex <- 1
  # scaleBar(shp.pu, pos = "bottomleft",
  #          cex=1,
  #          pt.cex = 1.1*cex,
  #          seg.len=10*cex,
  #          title.cex=cex,
  #          outer=FALSE)
  # suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
  dev.off()
  
###Koala values t7
  # Aggregate values by puid
  agg.df.org <- aggregate(t7 ~ LGA, data = df.org, FUN = mean)
  #agg.df.org$con_by_unimpvalue <- log(agg.df.org$con_by_unimpvalue)
  #agg.df.org$con_by_unimpvalue <- scale(agg.df.org$con_by_unimpvalue)
  
  ##Join budget values to shp file
  #pu.and.consben <- data.frame(df.to.merge$puid, consben.sol)
  colnames(agg.df.org) <- c("CADID", "koala_t7")
  shp.pu.joined <- merge(shp.pu, agg.df.org, by = "CADID")
  shp.pu.joined[is.na(shp.pu.joined$koala_t7)] <- 0
  #Export the map
  png(file=paste0(outfoldermaps, "./koala_t7.png"),  width=1000, height=1000)
  par(mar=c(0,0,0,0))
  #plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
  #plot the polygons without colour
  plot(shp.pu.joined)
  # Set the palette
  p <- colorRampPalette(c("white", "#009933", "#003300"))(128)
  palette(p)
  # Scale the values to the palette
  vals <- shp.pu.joined$koala_t7
  cols <- (vals - min(vals))/diff(range(vals))*127+1
  plot(shp.pu.joined, col=cols)
  
  #Add a legend
  levels <- unique(shp.pu.joined$koala_t7)
  levels <- round(levels, digits=8)
  levels <- sort(levels)
  col.levels <- unique(cols)
  col.levels <- sort(col.levels)
  
  # add a legend to your map
  legend("right",   # location of legend
         legend = levels, # categories or elements to render in
         # the legend
         fill = col.levels, # color palette to use to fill objects in legend.
         # title = "Suitability weighted koala
         # habitat km2",
         title = "Summed suitability",
         bty = "n",
         cex = 1.2)
  cex <- 1
  scaleBar(shp.pu, pos = "bottomleft",
           cex=1,
           pt.cex = 1.1*cex,
           seg.len=10*cex,
           title.cex=cex,
           outer=FALSE)
  suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
  dev.off()
  
  
  ###Koala values t0
  # Aggregate values by puid
  agg.df.org <- aggregate(t0 ~ LGA, data = df.org, FUN = mean)
  #agg.df.org$con_by_unimpvalue <- log(agg.df.org$con_by_unimpvalue)
  #agg.df.org$con_by_unimpvalue <- scale(agg.df.org$con_by_unimpvalue)
  
  ##Join budget values to shp file
  #pu.and.consben <- data.frame(df.to.merge$puid, consben.sol)
  colnames(agg.df.org) <- c("CADID", "koala_t0")
  shp.pu.joined <- merge(shp.pu, agg.df.org, by = "CADID")
  shp.pu.joined[is.na(shp.pu.joined$koala_t0)] <- 0
  #Export the map
  png(file=paste0(outfoldermaps, "./koala_t0.png"),  width=1000, height=1000)
  par(mar=c(0,0,0,0))
  #plotRGB(b.bg, maxpixels=max(500000, 1000*1000), ext=extent(shp.pu), asp=TRUE)
  #plot the polygons without colour
  plot(shp.pu.joined)
  # Set the palette
  p <- colorRampPalette(c("white", "#009933", "#003300"))(128)
  palette(p)
  # Scale the values to the palette
  vals <- shp.pu.joined$koala_t0
  cols <- (vals - min(vals))/diff(range(vals))*127+1
  plot(shp.pu.joined, col=cols)
  
  #Add a legend
  levels <- unique(shp.pu.joined$koala_t0)
  levels <- round(levels, digits=8)
  levels <- sort(levels)
  col.levels <- unique(cols)
  col.levels <- sort(col.levels)
  
  # add a legend to your map
  legend("right",   # location of legend
         legend = levels, # categories or elements to render in
         # the legend
         fill = col.levels, # color palette to use to fill objects in legend.
         # title = "Suitability weighted koala
         # habitat km2",
         title = "Summed suitability",
         bty = "n",
         cex = 1.2)
  cex <- 1
  scaleBar(shp.pu, pos = "bottomleft",
           cex=1,
           pt.cex = 1.1*cex,
           seg.len=10*cex,
           title.cex=cex,
           outer=FALSE)
  suppressWarnings(plot(v.bnd, col="black", lwd=2, add=TRUE))
  dev.off()
  
  
  
```


##Landholder preferences maps
```{r, include=FALSE}
properties.dbf <- read.dbf("./preprocessing/Propid_and_LGAid.dbf", as.is = FALSE)
probs <- read.csv("D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/bid_predictions/spatial_predictions_inf.csv")
land_v <- read.dbf("./preprocessing/props_pu_private_2ha_not_intense_not_water_notroadrail_predictors.dbf", as.is = FALSE)

df.to.merge <- data.frame(puid = unique(properties.dbf$LGA))
colnames(df.to.merge) <- c("LGA")
soc.dat <- merge(properties.dbf, probs, by = "NewPropID")
soc.dat <- merge(soc.dat, land_v, by = "NewPropID")

agg.MeanAdopt  <- aggregate(x = soc.dat[c("MeanAdopt")], by = soc.dat[c("LGA")], FUN = mean)
#agg.MeanAdopt  <- round(agg.MeanAdopt, digits = 1)
agg.MeanWTA  <- aggregate(x = soc.dat[c("MeanWTA")], by = soc.dat[c("LGA")], FUN = mean)
#agg.MeanWTA.tot  <- round(agg.MeanWTA.tot, digits = 1)
agg.MeanProp  <- aggregate(x = soc.dat[c("MeanProp")], by = soc.dat[c("LGA")], FUN = mean)
#agg.MeanProp  <- round(agg.MeanProp, digits = 1)
agg.LValHa  <- aggregate(x = soc.dat[c("LValHa")], by = soc.dat[c("LGA")], FUN = mean)
#agg.LValHa  <- round(agg.LValHa, digits = 1)

merged1 <- merge(df.to.merge, agg.MeanAdopt, by = "LGA")
merged2 <- merge(merged1, agg.MeanWTA, by = "LGA")
merged3 <- merge(merged2, agg.MeanProp, by = "LGA")
merged4 <- merge(merged3, agg.LValHa, by = "LGA")

# Write the data frame to a CSV file to create maps in ArcMap
write.csv(merged4, file = "D:/Linkage/DSF code/private_land_conservation_DSF/preprocessing/socialmodelsagg2.csv", row.names = FALSE)

# Check if the value is in the list
108012452 %in% unique(properties.dbf$LGA)


```

##Figure 5 - Benefit over budget plot when using all climate change scenarios
```{r, include=FALSE}
files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "scenario1+", full.names = T, recursive = TRUE)
a <- read.csv(files[127])
b <- read.csv(files[128])
c <- read.csv(files[129])
d <- read.csv(files[130])
e <- read.csv(files[121])
f <- read.csv(files[122])
g <- read.csv(files[123])
h <- read.csv(files[124])
i <- read.csv(files[125])
j <- read.csv(files[126])

all.consben.scen1 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen1.CCCMAR1t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[17])
b <- read.csv(files[18])
c <- read.csv(files[19])
d <- read.csv(files[20])
e <- read.csv(files[11])
f <- read.csv(files[12])
g <- read.csv(files[13])
h <- read.csv(files[14])
i <- read.csv(files[15])
j <- read.csv(files[16])

all.consben.scen1.CCCMAR2t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[27])
b <- read.csv(files[28])
c <- read.csv(files[29])
d <- read.csv(files[30])
e <- read.csv(files[21])
f <- read.csv(files[22])
g <- read.csv(files[23])
h <- read.csv(files[24])
i <- read.csv(files[25])
j <- read.csv(files[26])

all.consben.scen1.CCCMAR3t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[37])
b <- read.csv(files[38])
c <- read.csv(files[39])
d <- read.csv(files[40])
e <- read.csv(files[31])
f <- read.csv(files[32])
g <- read.csv(files[33])
h <- read.csv(files[34])
i <- read.csv(files[35])
j <- read.csv(files[36])

all.consben.scen1.CSIROMAR1t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[47])
b <- read.csv(files[48])
c <- read.csv(files[49])
d <- read.csv(files[50])
e <- read.csv(files[41])
f <- read.csv(files[42])
g <- read.csv(files[43])
h <- read.csv(files[44])
i <- read.csv(files[45])
j <- read.csv(files[46])

all.consben.scen1.CSIROMAR2t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[57])
b <- read.csv(files[58])
c <- read.csv(files[59])
d <- read.csv(files[60])
e <- read.csv(files[51])
f <- read.csv(files[52])
g <- read.csv(files[53])
h <- read.csv(files[54])
i <- read.csv(files[55])
j <- read.csv(files[56])

all.consben.scen1.CSIROMAR3t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[67])
b <- read.csv(files[68])
c <- read.csv(files[69])
d <- read.csv(files[70])
e <- read.csv(files[61])
f <- read.csv(files[62])
g <- read.csv(files[63])
h <- read.csv(files[64])
i <- read.csv(files[65])
j <- read.csv(files[66])

all.consben.scen1.ECHAMR1t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[77])
b <- read.csv(files[78])
c <- read.csv(files[79])
d <- read.csv(files[80])
e <- read.csv(files[71])
f <- read.csv(files[72])
g <- read.csv(files[73])
h <- read.csv(files[74])
i <- read.csv(files[75])
j <- read.csv(files[76])

all.consben.scen1.ECHAMR2t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[87])
b <- read.csv(files[88])
c <- read.csv(files[89])
d <- read.csv(files[90])
e <- read.csv(files[81])
f <- read.csv(files[82])
g <- read.csv(files[83])
h <- read.csv(files[84])
i <- read.csv(files[85])
j <- read.csv(files[86])

all.consben.scen1.ECHAMR3t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[97])
b <- read.csv(files[98])
c <- read.csv(files[99])
d <- read.csv(files[100])
e <- read.csv(files[91])
f <- read.csv(files[92])
g <- read.csv(files[93])
h <- read.csv(files[94])
i <- read.csv(files[95])
j <- read.csv(files[96])

all.consben.scen1.MIROCR1t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[107])
b <- read.csv(files[108])
c <- read.csv(files[109])
d <- read.csv(files[110])
e <- read.csv(files[101])
f <- read.csv(files[102])
g <- read.csv(files[103])
h <- read.csv(files[104])
i <- read.csv(files[105])
j <- read.csv(files[106])

all.consben.scen1.MIROCR2t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

a <- read.csv(files[117])
b <- read.csv(files[118])
c <- read.csv(files[119])
d <- read.csv(files[120])
e <- read.csv(files[111])
f <- read.csv(files[112])
g <- read.csv(files[113])
h <- read.csv(files[114])
i <- read.csv(files[115])
j <- read.csv(files[116])

all.consben.scen1.MIROCR3t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "scenario2_budget", full.names = T, recursive = TRUE)
files <- files[2:11]
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "CCCMAR1t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.CCCMAR1t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "CCCMAR2t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.CCCMAR2t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "CCCMAR3t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.CCCMAR3t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "CSIROMAR1t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.CSIROMAR1t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "CSIROMAR2t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.CSIROMAR2t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "CSIROMAR3t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.CSIROMAR3t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "ECHAMR1t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.ECHAMR1t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "ECHAMR2t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.ECHAMR2t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "ECHAMR3t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.ECHAMR3t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "MIROCR1t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.MIROCR1t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "MIROCR2t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.MIROCR2t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)

files <- list.files("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/vals_v12/", pattern = "MIROCR3t7", full.names = T, recursive = TRUE)
a <- read.csv(files[7])
b <- read.csv(files[8])
c <- read.csv(files[9])
d <- read.csv(files[10])
e <- read.csv(files[1])
f <- read.csv(files[2])
g <- read.csv(files[3])
h <- read.csv(files[4])
i <- read.csv(files[5])
j <- read.csv(files[6])

all.consben.scen2.MIROCR3t7 <- c(a$cons.ben, b$cons.ben, c$cons.ben, d$cons.ben, e$cons.ben, f$cons.ben, g$cons.ben, h$cons.ben, i$cons.ben, j$cons.ben)


df <- data.frame(rep(b.vec, 26), c(all.consben.scen1, all.consben.scen1.CCCMAR1t7, all.consben.scen1.CCCMAR2t7, all.consben.scen1.CCCMAR3t7, all.consben.scen1.CSIROMAR1t7, all.consben.scen1.CSIROMAR2t7, all.consben.scen1.CSIROMAR3t7, all.consben.scen1.ECHAMR1t7, all.consben.scen1.ECHAMR2t7, all.consben.scen1.ECHAMR3t7, all.consben.scen1.MIROCR1t7, all.consben.scen1.MIROCR2t7, all.consben.scen1.MIROCR3t7, all.consben.scen2, all.consben.scen2.CCCMAR1t7, all.consben.scen2.CCCMAR2t7, all.consben.scen2.CCCMAR3t7, all.consben.scen2.CSIROMAR1t7, all.consben.scen2.CSIROMAR2t7, all.consben.scen2.CSIROMAR3t7, all.consben.scen2.ECHAMR1t7, all.consben.scen2.ECHAMR2t7, all.consben.scen2.ECHAMR3t7, all.consben.scen2.MIROCR1t7, all.consben.scen2.MIROCR2t7, all.consben.scen2.MIROCR3t7), c(rep("Scenario1", 10), rep("Scenario1.CCCMAR1t7", 10), rep("Scenario1.CCCMAR2t7", 10), rep("Scenario1.CCCMAR3t7", 10), rep("Scenario1.CSIROMAR1t7", 10), rep("Scenario1.CSIROMAR2t7", 10), rep("Scenario1.CSIROMAR3t7", 10), rep("Scenario1.ECHAMR1t7", 10), rep("Scenario1.ECHAMR2t7", 10), rep("Scenario1.ECHAMR3t7", 10), rep("Scenario1.MIROCR1t7", 10), rep("Scenario1.MIROCR2t7", 10), rep("Scenario1.MIROCR3t7", 10), rep("Scenario2", 10), rep("Scenario2.CCCMAR1t7", 10), rep("Scenario2.CCCMAR2t7", 10), rep("Scenario2.CCCMAR3t7", 10), rep("Scenario2.CSIROMAR1t7", 10), rep("Scenario2.CSIROMAR2t7", 10), rep("Scenario2.CSIROMAR3t7", 10), rep("Scenario2.ECHAMR1t7", 10), rep("Scenario2.ECHAMR2t7", 10), rep("Scenario2.ECHAMR3t7", 10), rep("Scenario2.MIROCR1t7", 10), rep("Scenario2.MIROCR2t7", 10), rep("Scenario2.MIROCR3t7", 10)), c(rep("Baseline", 10), rep("CCCMAR1t7", 10), rep("CCCMAR2t7", 10), rep("CCCMAR3t7", 10), rep("CSIROMAR1t7", 10), rep("CSIROMAR2t7", 10), rep("CSIROMAR3t7", 10), rep("ECHAMR1t7", 10), rep("ECHAMR2t7", 10), rep("ECHAMR3t7", 10), rep("MIROCR1t7", 10), rep("MIROCR2t7", 10), rep("MIROCR3t7", 10), rep("Scenario2", 10), rep("Scenario2.CCCMAR1t7", 10), rep("Scenario2.CCCMAR2t7", 10), rep("Scenario2.CCCMAR3t7", 10), rep("Scenario2.CSIROMAR1t7", 10), rep("Scenario2.CSIROMAR2t7", 10), rep("Scenario2.CSIROMAR3t7", 10), rep("Scenario2.ECHAMR1t7", 10), rep("Scenario2.ECHAMR2t7", 10), rep("Scenario2.ECHAMR3t7", 10), rep("Scenario2.MIROCR1t7", 10), rep("Scenario2.MIROCR2t7", 10), rep("Scenario2.MIROCR3t7", 10)))

colnames(df) <- c("Budget", "Consben", "Scenario", "Climatic Conditions")

df$Budget <- df$Budget/1000000
#df$Consben <- df$Consben/1000000

###Distance from the optimal solution is the value of the solution - all.consben.scen3

df$Scenario <- factor(df$Scenario, levels = c('Scenario1', 'Scenario1.CCCMAR1t7', 'Scenario1.CCCMAR2t7', 'Scenario1.CCCMAR3t7', 'Scenario1.CSIROMAR1t7', 'Scenario1.CSIROMAR2t7', 'Scenario1.CSIROMAR3t7', 'Scenario1.ECHAMR1t7', 'Scenario1.ECHAMR2t7', 'Scenario1.ECHAMR3t7', 'Scenario1.MIROCR1t7', 'Scenario1.MIROCR2t7', 'Scenario1.MIROCR3t7', 'Scenario2', 'Scenario2.CCCMAR1t7', 'Scenario2.CCCMAR2t7', 'Scenario2.CCCMAR3t7', 'Scenario2.CSIROMAR1t7', 'Scenario2.CSIROMAR2t7', 'Scenario2.CSIROMAR3t7', 'Scenario2.ECHAMR1t7', 'Scenario2.ECHAMR2t7', 'Scenario2.ECHAMR3t7', 'Scenario2.MIROCR1t7', 'Scenario2.MIROCR2t7', 'Scenario2.MIROCR3t7'))

# Add a new column that is half one value and half the other
df$Approach <- ifelse(grepl("Scenario1+", df$Scenario), "Climate change informed", "Integrated approach")
df$Approach <- ifelse(grepl("Baseline", df$`Climatic Conditions`), "Business as usual", df$Approach)
df$Approach <- ifelse(grepl("^Scenario2$", df$`Climatic Conditions`), "Landholder informed", df$Approach)


View(df)

library(ggplot2)
library(RColorBrewer)

#TO DO
#Need to create different lines for the BAU with and without CC

colors <- brewer.pal(n = 12, name = "Paired")
colors <- c(colors, "#FF00FF", colors, "#FF00FF")
# Plot the data with custom line types and colors

s <- ggplot(df, aes(x = Budget, y = Consben, group = Scenario, linetype = Approach, color = `Climatic Conditions`)) + 
  geom_line(size = 1) +
  scale_color_manual(values = colors) +
  scale_linetype_manual(values = c("solid", "dashed", "dotted", "twodash")) +  # Specify the line types here
  theme(panel.grid = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"),
        legend.background = element_blank()) +
  xlab("Budget M $AUD") +
  ylab("Summed koala landscape capacity")



ggsave("E:/Linkage/DSF code/private_land_conservation_DSF/outputs_v12/figures/df_lines_cons_incl.png", s, width = 10, height = 6)

##############First attempt

# p <- ggplot(df, aes(x = Budget, y = Consben, group = Scenario)) +
#   #, linetype = line_type
#   #colours
#   scale_color_manual(values=c("#548235", "red", "black", "#9A6324", "#469990", "#000075", "#f58231", "#ffe119", "#bfef45", "#42d4f4", "#4363d8", "#911eb4", "#f032e6", "#fabed4", "#ffd8b1", "#fffac8", "#aaffc3", "#dcbeff", "#ffa07a", "pink", "#800000", "#fabed4", "#ffd8b1", "#fffac8", "#aaffc3", "#dcbeff"))+
#   # geom_line(aes(color = Scenario), size = 0.5) +
#   #scale_linetype_manual(values = c("dashed", "solid")) +
#   scale_linetype_manual(values = c("Scenario1" = "dashed", "Scenario2" = "solid", "Scenario1.CCCMAR1t7" = "dashed", "Scenario1.CCCMAR2t7" = "dashed", "Scenario1.CCCMAR3t7" = "dashed", "Scenario1.CSIROMAR1t7" = "dashed", "Scenario1.CSIROMAR2t7" = "dashed", "Scenario1.CSIROMAR3t7" = "dashed", "Scenario1.ECHAMR1t7" = "dashed", "Scenario1.ECHAMR2t7" = "dashed", "Scenario1.ECHAMR3t7" = "dashed", "Scenario1.MIROCR1t7" = "dashed", "Scenario1.MIROCR2t7" = "dashed", "Scenario1.MIROCR3t7" = "dashed", "Scenario2.CCCMAR1t7" = "dashed", "Scenario2.CCCMAR2t7" = "dashed", "Scenario2.CCCMAR3t7" = "dashed", "Scenario2.CSIROMAR1t7" = "dashed", "Scenario2.CSIROMAR2t7" = "dashed", "Scenario2.CSIROMAR3t7" = "dashed", "Scenario2.ECHAMR1t7" = "dashed", "Scenario2.ECHAMR2t7" = "dashed", "Scenario2.ECHAMR3t7" = "dashed", "Scenario2.MIROCR1t7" = "dashed", "Scenario2.MIROCR2t7" = "dashed", "Scenario2.MIROCR3t7" = "dashed")) +
#   #geom_point(aes(color = Scenario), size = 0)+
#   # scale_fill_discrete(labels=c('test', 'Scenario2', 'Scenario3', 'cccma_cgcm31', 'ccsr_miroc32hi', 'ccsr_miroc32med', 'cnrm_cm3', 'csiro_mk30', 'gfdl_cm20',      'gfdl_cm21', 'giss_modeleh', 'giss_modeler', 'iap_fgoals10g', 'inm_cm30', 'ipsl_cm4', 'mpi_echam5', 'mri_cgcm232a', 'ncar_ccsm30', 'ncar_pcm1', 'ukmo_hadcm3',   'ukmo_hadcm1'))+
#   xlab("Budget M $AUD") +
#   ylab("Suitability-weighted koala habitat (km2)")+
#   geom_line(aes(color = Scenario), linewidth = 1) +
#   geom_point(aes(color = Scenario), size = 0)+
#   scale_x_continuous(expand = c(0, 0)) + 
#   scale_y_continuous(expand = c(0, 0))+
#   theme_bw()
#   #guides(linetype = guide_legend(
#   #   override.aes = list(
#   #     linetype = c("dashed", "solid", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed", "dashed")
#   #   ),
#   #   title = "Scenario"
#   # ))
#   
#   x <- p + 
#   # theme(
#   # legend.position="top",
#   # legend.text=element_text(size=5),
#   # legend.title=element_blank(),
#   # axis.text.x=element_text(size=15),
#   # axis.text.y=element_text(size=15),
#   # axis.title.y = element_text(size = rel(1.8)),
#   # axis.title.x = element_text(size = rel(1.8)), 
#   # # Remove panel border
#   # panel.border = element_blank(),  
#   # # Remove panel grid lines
#   # panel.grid.major = element_blank(),
#   # panel.grid.minor = element_blank(),
#   # # Remove panel background
#   # panel.background = element_blank(),
#   # # Add axis line
#   # axis.line = element_line(colour = "grey")+
#   # #Remove grey from legend
#   # theme_set(theme_bw() + theme(legend.key=element_blank())))
#   
#   plot(x)
#   
# 
#  ##No legend
#  p <- ggplot(df, aes(x = Budget, y = Consben, group = Scenario)) +
#   #colours
#   scale_color_manual(values=c("#548235", "red", "black", "#9A6324", "#469990", "#000075", "#f58231", "#ffe119", "#bfef45", "#42d4f4", "#4363d8", "#911eb4",       "#f032e6", "#fabed4", "#ffd8b1", "#fffac8", "#aaffc3", "#dcbeff", "#ffa07a", "pink", "#800000"))+
#   geom_line(aes(color = Scenario), size = 0.5) +
#   geom_point(aes(color = Scenario), size = 0)+
#   scale_fill_discrete(labels=c('test', 'Scenario2', 'Scenario3', 'cccma_cgcm31', 'ccsr_miroc32hi', 'ccsr_miroc32med', 'cnrm_cm3', 'csiro_mk30', 'gfdl_cm20',      'gfdl_cm21', 'giss_modeleh', 'giss_modeler', 'iap_fgoals10g', 'inm_cm30', 'ipsl_cm4', 'mpi_echam5', 'mri_cgcm232a', 'ncar_ccsm30', 'ncar_pcm1', 'ukmo_hadcm3',   'ukmo_hadcm1'))+
#   xlab("Budget M $AUD") +
#   ylab("Suitability-weighted koala habitat (km2)")+
#   geom_line(aes(color = Scenario), size = 1) +
#   geom_point(aes(color = Scenario), size = 0) +
#   scale_x_continuous(expand = c(0, 0)) + 
#   scale_y_continuous(expand = c(0, 0))
#   
#   x <- p + theme(
#   legend.position="none",
#   legend.title=element_blank(),
#   axis.text.x=element_text(size=15),
#   axis.text.y=element_text(size=15),
#   axis.title.y = element_text(size = rel(1.8)),
#   axis.title.x = element_text(size = rel(1.8)), 
#   # Remove panel border
#   panel.border = element_blank(),  
#   # Remove panel grid lines
#   panel.grid.major = element_blank(),
#   panel.grid.minor = element_blank(),
#   # Remove panel background
#   panel.background = element_blank(),
#   # Add axis line
#   axis.line = element_line(colour = "grey")+
#   #Remove grey from legend
#   theme_set(theme_bw() + theme(legend.key=element_blank())))
# 
#  ggsave("df_lines_cons_nolegend.png",
#   x
#   )
# 
#  ##EXCLUDE THE CONSERVATION SCENARIO
#  
# df.nocons <- data.frame(rep(b.vec, 20), c(all.consben.scen2, all.consben.scen3, all.consben.cccma_cgcm31,all.consben.ccsr_miroc32hi, all.consben.ccsr_miroc32med, all.consben.cnrm_cm3, all.consben.csiro_mk30, all.consben.gfdl_cm20, all.consben.gfdl_cm21, all.consben.giss_modeleh, all.consben.giss_modeler, all.consben.iap_fgoals10g, all.consben.inm_cm30, all.consben.ipsl_cm4, all.consben.mpi_echam5, all.consben.mri_cgcm232a, all.consben.ncar_ccsm30, all.consben.ncar_pcm1, all.consben.ukmo_hadcm3, all.consben.ukmo_hadgem1), c(rep("Scenario2", 10), rep("Scenario3", 10), rep("cccma_cgcm31", 10), rep("ccsr_miroc32hi", 10), rep("ccsr_miroc32med", 10), rep("cnrm_cm3", 10), rep("csiro_mk30", 10), rep("gfdl_cm20", 10), rep("gfdl_cm21", 10), rep("giss_modeleh", 10), rep("giss_modeler", 10), rep("iap_fgoals10g", 10), rep("inm_cm30", 10), rep("ipsl_cm4", 10), rep("mpi_echam5", 10), rep("mri_cgcm232a", 10), rep("ncar_ccsm30", 10), rep("ncar_pcm1", 10), rep("ukmo_hadcm3", 10), rep("ukmo_hadcm1", 10)))
#  
# colnames(df.nocons) <- c("Budget", "Consben", "Scenario")
# 
# df.nocons$Scenario <- factor(df.nocons$Scenario, levels = c('Scenario2', 'Scenario3', 'cccma_cgcm31', 'ccsr_miroc32hi', 'ccsr_miroc32med', 'cnrm_cm3', 'csiro_mk30', 'gfdl_cm20', 'gfdl_cm21', 'giss_modeleh', 'giss_modeler', 'iap_fgoals10g', 'inm_cm30', 'ipsl_cm4', 'mpi_echam5', 'mri_cgcm232a', 'ncar_ccsm30', 'ncar_pcm1', 'ukmo_hadcm3', 'ukmo_hadcm1'))
# 
# df.nocons$Budget <- df.nocons$Budget/1000000
# df.nocons$Consben <- df.nocons$Consben/1000000
# 
#  p <- ggplot(df.nocons, aes(x = Budget, y = Consben, group = Scenario)) +
#   #colours
#   scale_color_manual(values=c("red", "black", "#9A6324", "#469990", "#000075", "#f58231", "#ffe119", "#bfef45", "#42d4f4", "#4363d8", "#911eb4",       "#f032e6", "#fabed4", "#ffd8b1", "#fffac8", "#aaffc3", "#dcbeff", "#ffa07a", "pink", "#800000"))+
#   geom_line(aes(color = Scenario), size = 0.5) +
#   geom_point(aes(color = Scenario), size = 0)+
#   scale_fill_discrete(labels=c('test', 'Scenario2', 'Scenario3', 'cccma_cgcm31', 'ccsr_miroc32hi', 'ccsr_miroc32med', 'cnrm_cm3', 'csiro_mk30', 'gfdl_cm20',      'gfdl_cm21', 'giss_modeleh', 'giss_modeler', 'iap_fgoals10g', 'inm_cm30', 'ipsl_cm4', 'mpi_echam5', 'mri_cgcm232a', 'ncar_ccsm30', 'ncar_pcm1', 'ukmo_hadcm3',   'ukmo_hadcm1'))+
#   xlab("Budget M $AUD") +
#   ylab("Suitability-weighted koala habitat (km2)")+
#   geom_line(aes(color = Scenario), size = 1) +
#   geom_point(aes(color = Scenario), size = 0)
#   
#   x <- p + theme(
#   legend.position="non",
#   legend.title=element_blank(),
#   axis.text.x=element_text(size=15),
#   axis.text.y=element_text(size=15),
#   axis.title.y = element_text(size = rel(1.8)),
#   axis.title.x = element_text(size = rel(1.8)), 
#   # Remove panel border
#   panel.border = element_blank(),  
#   # Remove panel grid lines
#   panel.grid.major = element_blank(),
#   panel.grid.minor = element_blank(),
#   # Remove panel background
#   panel.background = element_blank(),
#   # Add axis line
#   axis.line = element_line(colour = "grey")+
#   #Remove grey from legend
#   theme_set(theme_bw() + theme(legend.key=element_blank())))
# 
#  ggsave("df_lines_nocons_nolegend.png",
#   x
#   )
#  

##DIFFERENCE PLOTS
# df.diff <- data.frame(rep(b.vec, 21), c(all.consben.scen1-all.consben.scen3, all.consben.scen2-all.consben.scen3, all.consben.scen3-all.consben.scen3, all.consben.cccma_cgcm31-all.consben.scen3,all.consben.ccsr_miroc32hi-all.consben.scen3, all.consben.ccsr_miroc32med-all.consben.scen3, all.consben.cnrm_cm3-all.consben.scen3, all.consben.csiro_mk30-all.consben.scen3, all.consben.gfdl_cm20-all.consben.scen3, all.consben.gfdl_cm21-all.consben.scen3, all.consben.giss_modeleh-all.consben.scen3, all.consben.giss_modeler-all.consben.scen3, all.consben.iap_fgoals10g-all.consben.scen3, all.consben.inm_cm30-all.consben.scen3, all.consben.ipsl_cm4-all.consben.scen3, all.consben.mpi_echam5-all.consben.scen3, all.consben.mri_cgcm232a-all.consben.scen3, all.consben.ncar_ccsm30-all.consben.scen3, all.consben.ncar_pcm1-all.consben.scen3, all.consben.ukmo_hadcm3-all.consben.scen3, all.consben.ukmo_hadgem1-all.consben.scen3), c(rep("Scenario1", 10), rep("Scenario2", 10), rep("Scenario3", 10), rep("cccma_cgcm31", 10), rep("ccsr_miroc32hi", 10), rep("ccsr_miroc32med", 10), rep("cnrm_cm3", 10), rep("csiro_mk30", 10), rep("gfdl_cm20", 10), rep("gfdl_cm21", 10), rep("giss_modeleh", 10), rep("giss_modeler", 10), rep("iap_fgoals10g", 10), rep("inm_cm30", 10), rep("ipsl_cm4", 10), rep("mpi_echam5", 10), rep("mri_cgcm232a", 10), rep("ncar_ccsm30", 10), rep("ncar_pcm1", 10), rep("ukmo_hadcm3", 10), rep("ukmo_hadcm1", 10)))
# 
# colnames(df.diff) <- c("Budget", "Consben", "Scenario")
# 
# df.diff$Scenario <- factor(df.diff$Scenario, levels = c('Scenario1', 'Scenario2', 'Scenario3', 'cccma_cgcm31', 'ccsr_miroc32hi', 'ccsr_miroc32med', 'cnrm_cm3', 'csiro_mk30', 'gfdl_cm20', 'gfdl_cm21', 'giss_modeleh', 'giss_modeler', 'iap_fgoals10g', 'inm_cm30', 'ipsl_cm4', 'mpi_echam5', 'mri_cgcm232a', 'ncar_ccsm30', 'ncar_pcm1', 'ukmo_hadcm3', 'ukmo_hadcm1'))
#  
# df.diff$Budget <- df.diff$Budget/1000000
# df.diff$Consben <- df.diff$Consben/1000000
# 
# library(ggplot2)
# p <- ggplot(df.diff, aes(x = Budget, y = Consben, group = Scenario)) +
#   #colours
#   scale_color_manual(values=c("#548235", "red", "black", "#9A6324", "#469990", "#000075", "#f58231", "#ffe119", "#bfef45", "#42d4f4", "#4363d8", "#911eb4",       "#f032e6", "#fabed4", "#ffd8b1", "#fffac8", "#aaffc3", "#dcbeff", "#ffa07a", "pink", "#800000"))+
#   geom_line(aes(color = Scenario), size = 0.5) +
#   geom_point(aes(color = Scenario), size = 0)+
#   scale_fill_discrete(labels=c('test', 'Scenario2', 'Scenario3', 'cccma_cgcm31', 'ccsr_miroc32hi', 'ccsr_miroc32med', 'cnrm_cm3', 'csiro_mk30', 'gfdl_cm20',      'gfdl_cm21', 'giss_modeleh', 'giss_modeler', 'iap_fgoals10g', 'inm_cm30', 'ipsl_cm4', 'mpi_echam5', 'mri_cgcm232a', 'ncar_ccsm30', 'ncar_pcm1', 'ukmo_hadcm3',   'ukmo_hadcm1'))+
#   xlab("Budget M $AUD") +
#   ylab("Suitability-weighted koala habitat (km2)")+
#   geom_line(aes(color = Scenario), size = 1) +
#   geom_point(aes(color = Scenario), size = 0)
#   
#   x <- p + theme(
#   legend.position="none",
#   legend.title=element_blank(),
#   axis.text.x=element_text(size=15),
#   axis.text.y=element_text(size=15),
#   axis.title.y = element_text(size = rel(1.8)),
#   axis.title.x = element_text(size = rel(1.8)), 
#   # Remove panel border
#   panel.border = element_blank(),  
#   # Remove panel grid lines
#   panel.grid.major = element_blank(),
#   panel.grid.minor = element_blank(),
#   # Remove panel background
#   panel.background = element_blank(),
#   # Add axis line
#   axis.line = element_line(colour = "grey")+
#   #Remove grey from legend
#   theme_set(theme_bw() + theme(legend.key=element_blank())))
# 
#  ggsave("df_diff_lines_cons_incl.png",
#   x
#   ) 
#  
# 
# #Remove the cons scen - diff plot
# df.diff <- data.frame(rep(b.vec, 20), c(all.consben.scen2-all.consben.scen3, all.consben.scen3-all.consben.scen3, all.consben.cccma_cgcm31-all.consben.scen3,all.consben.ccsr_miroc32hi-all.consben.scen3, all.consben.ccsr_miroc32med-all.consben.scen3, all.consben.cnrm_cm3-all.consben.scen3, all.consben.csiro_mk30-all.consben.scen3, all.consben.gfdl_cm20-all.consben.scen3, all.consben.gfdl_cm21-all.consben.scen3, all.consben.giss_modeleh-all.consben.scen3, all.consben.giss_modeler-all.consben.scen3, all.consben.iap_fgoals10g-all.consben.scen3, all.consben.inm_cm30-all.consben.scen3, all.consben.ipsl_cm4-all.consben.scen3, all.consben.mpi_echam5-all.consben.scen3, all.consben.mri_cgcm232a-all.consben.scen3, all.consben.ncar_ccsm30-all.consben.scen3, all.consben.ncar_pcm1-all.consben.scen3, all.consben.ukmo_hadcm3-all.consben.scen3, all.consben.ukmo_hadgem1-all.consben.scen3), c(rep("Scenario2", 10), rep("Scenario3", 10), rep("cccma_cgcm31", 10), rep("ccsr_miroc32hi", 10), rep("ccsr_miroc32med", 10), rep("cnrm_cm3", 10), rep("csiro_mk30", 10), rep("gfdl_cm20", 10), rep("gfdl_cm21", 10), rep("giss_modeleh", 10), rep("giss_modeler", 10), rep("iap_fgoals10g", 10), rep("inm_cm30", 10), rep("ipsl_cm4", 10), rep("mpi_echam5", 10), rep("mri_cgcm232a", 10), rep("ncar_ccsm30", 10), rep("ncar_pcm1", 10), rep("ukmo_hadcm3", 10), rep("ukmo_hadcm1", 10)))
# 
# colnames(df.diff) <- c("Budget", "Consben", "Scenario")
# 
# df.diff$Scenario <- factor(df.diff$Scenario, levels = c('Scenario2', 'Scenario3', 'cccma_cgcm31', 'ccsr_miroc32hi', 'ccsr_miroc32med', 'cnrm_cm3', 'csiro_mk30', 'gfdl_cm20', 'gfdl_cm21', 'giss_modeleh', 'giss_modeler', 'iap_fgoals10g', 'inm_cm30', 'ipsl_cm4', 'mpi_echam5', 'mri_cgcm232a', 'ncar_ccsm30', 'ncar_pcm1', 'ukmo_hadcm3', 'ukmo_hadcm1'))
#  
# df.diff$Budget <- df.diff$Budget/1000000
# df.diff$Consben <- df.diff$Consben/1000000
# 
# library(ggplot2)
# p <- ggplot(df.diff, aes(x = Budget, y = Consben, group = Scenario)) +
#   #colours
#   scale_color_manual(values=c("red", "black", "#9A6324", "#469990", "#000075", "#f58231", "#ffe119", "#bfef45", "#42d4f4", "#4363d8", "#911eb4",       "#f032e6", "#fabed4", "#ffd8b1", "#fffac8", "#aaffc3", "#dcbeff", "#ffa07a", "pink", "#800000"))+
#   geom_line(aes(color = Scenario), size = 0.5) +
#   geom_point(aes(color = Scenario), size = 0)+
#   scale_fill_discrete(labels=c('Scenario2', 'Scenario3', 'cccma_cgcm31', 'ccsr_miroc32hi', 'ccsr_miroc32med', 'cnrm_cm3', 'csiro_mk30', 'gfdl_cm20',      'gfdl_cm21', 'giss_modeleh', 'giss_modeler', 'iap_fgoals10g', 'inm_cm30', 'ipsl_cm4', 'mpi_echam5', 'mri_cgcm232a', 'ncar_ccsm30', 'ncar_pcm1', 'ukmo_hadcm3',   'ukmo_hadcm1'))+
#   xlab("Budget M $AUD") +
#   ylab("Suitability-weighted koala habitat (km2)")+
#   geom_line(aes(color = Scenario), size = 1) +
#   geom_point(aes(color = Scenario), size = 0)
#   
#   x <- p + theme(
#   legend.position="none",
#   legend.title=element_blank(),
#   axis.text.x=element_text(size=15),
#   axis.text.y=element_text(size=15),
#   axis.title.y = element_text(size = rel(1.8)),
#   axis.title.x = element_text(size = rel(1.8)), 
#   # Remove panel border
#   panel.border = element_blank(),  
#   # Remove panel grid lines
#   panel.grid.major = element_blank(),
#   panel.grid.minor = element_blank(),
#   # Remove panel background
#   panel.background = element_blank(),
#   # Add axis line
#   axis.line = element_line(colour = "grey")+
#   #Remove grey from legend
#   theme_set(theme_bw() + theme(legend.key=element_blank())))
# 
#  ggsave("df_diff_lines_nocons.png",
#   x
#   ) 
#  

```



